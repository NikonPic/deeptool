# AUTOGENERATED! DO NOT EDIT! File to edit: nbs\33_rnn_vae.ipynb (unless otherwise specified).

__all__ = ['mod_batch', 'RNN_AE', 'RNN_VAE', 'RNN_IN_VAE', 'Creator_RNN_AE']

# Cell

import torch
from torch import nn, optim
from ..architecture import Encoder, Decoder, DownUpConv
from ..utils import Tracker

# Cell


def mod_batch(batch, key="img"):
    """
    transform the batch to be compatible with the network by permuting
    """
    if len(batch[key].shape) > 4:
        batch[key] = batch[key][0, :, :, :, :]
        batch[key] = batch[key].permute(1, 0, 2, 3)
    return batch

# Cell


class RNN_AE(nn.Module):

    def __init__(self, device, args):
        """
        The recurrent autoencoder for compressing 3d data.
        It compresses in 2d while (hopefully) maintaining the spatial relation between layers
        """
        super(RNN_AE, self).__init__()
        self.device = device

        # 1. create the convolutional Encoder
        args.dim = 2
        self.conv_part_enc = DownUpConv(args, pic_size=args.pic_size, n_fea_in=len(
            args.perspectives), n_fea_next=args.n_fea_up, depth=1).to(self.device)

        # save important features
        max_fea, min_size = self.conv_part_enc.max_fea, self.conv_part_enc.min_size
        self.n_z, self.max_fea, self.min_size = args.n_z, max_fea, min_size

        self.view_arr = [-1, max_fea * min_size**2]  # as flat vector
        self.view_conv = [-1, max_fea, min_size, min_size]  # as conv block
        self.view_track = [1, len(args.perspectives), -1,
                           args.pic_size, args.pic_size]

        # 2. Apply FC- Encoder Part
        self.fc_part_enc = nn.Sequential(
            nn.Linear(max_fea*min_size*min_size, max_fea*min_size),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(max_fea*min_size, max_fea),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(max_fea, args.n_z),
        ).to(self.device)

        # 3. Transition Layer:
        if args.rnn_active:
            # Apply a RECURRENCE
            self.transition = nn.GRU(args.n_z, args.n_z, 1).to(self.device)
        else:
            # simple Identity
            self.transition = nn.Sequential()

        # 4. Apply FC-Decoder Part
        self.fc_part_dec = nn.Sequential(
            nn.Linear(args.n_z, max_fea),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(max_fea, max_fea*min_size),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(max_fea*min_size, max_fea*min_size*min_size),
        ).to(self.device)

        # 5. create the convolutional Decoder
        self.conv_part_dec = DownUpConv(
            args, pic_size=args.pic_size, n_fea_in=len(
                args.perspectives), n_fea_next=args.n_fea_down, depth=1, move='up').to(self.device)

        # the standard loss
        self.mse_loss = nn.MSELoss(reduction='sum')

        # the optimizer
        self.optimizer = optim.Adam(self.parameters(), lr=args.lr)

        # reset the dimension
        args.dim = 3

        # Setup the tracker to visualize the progress
        if args.track:
            self.tracker = Tracker(args)

    def watch_progress(self, test_data, iteration):
        """Outsourced to Tracker"""
        self.tracker.track_progress(self, test_data, iteration)

    def rnn_transition(self, x):
        """
        take the matrix of encoded input slices and apply the RNN part
        """
        # reshape
        x = x.reshape([-1, 1, self.n_z])
        # apply GRU layer
        x, _ = self.transition(x)
        # reshape
        x = x.reshape([-1, self.n_z])
        return x

    def encode(self, x):
        x = self.conv_part_enc(x)
        x = x.reshape(self.view_arr)
        x = self.fc_part_enc(x)
        return x

    def decode(self, x):
        x = self.fc_part_dec(x)
        x = x.reshape(self.view_conv)
        x = self.conv_part_dec(x)
        return x

    def prep_input(self, batch):
        self.zero_grad()
        batch = mod_batch(batch)
        img = batch['img'].to(self.device)
        return img

    def forward(self, batch, update=True):
        """
        calculate the forward pass
        """
        # prepare
        img = self.prep_input(batch)
        # encode:
        x = self.encode(img)
        # apply the GRU transition
        x = self.rnn_transition(x)
        # decode
        x = self.decode(x)
        # calc loss
        loss = self.mse_loss(img, x)

        if update:
            loss.backward()
            self.optimizer.step()
            return x

        else:
            tr_data = {}
            tr_data["loss"] = loss.item()

        return x, tr_data

# Cell


class RNN_VAE(RNN_AE):
    """
    inherit from RNN_AE and add the variational part
    """

    def __init__(self, device, args):
        #super(RNN_AE, self).__init__(device, args)
        RNN_AE.__init__(self, device, args)
        # 2. rewrite FC- Encoder Part
        max_fea, min_size = self.max_fea, self.min_size
        self.fc_part_enc = nn.Sequential(
            nn.Linear(max_fea*min_size*min_size, max_fea*min_size),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(max_fea*min_size, max_fea),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(max_fea, 2 * args.n_z),
        ).to(self.device)
        # get the kl facor
        self.gamma = args.gamma

    def vae_sampling(self, x):
        mu, log_sig2 = x.chunk(2, dim=1)
        # get random matrix
        eps = torch.rand_like(
            mu, device=self.device)
        # sample together
        z = mu + torch.exp(torch.mul(0.5, log_sig2)) * eps
        return z, mu, log_sig2

    def kl_loss(self, mu, log_sig2):
        return -0.5 * torch.sum(1 - torch.pow(mu, 2) - torch.exp(log_sig2) + log_sig2)

    def forward(self, batch, update=True):
        # prepare
        img = self.prep_input(batch)
        # encode
        x = self.encode(img)
        # apply the vae sampling
        x, mu, log_sig2 = self.vae_sampling(x)
        # now the transition
        x = self.rnn_transition(x)
        # decode
        x = self.decode(x)

        # get loss
        ae_loss = self.mse_loss(img, x)
        vae_loss = self.kl_loss(mu, log_sig2)
        loss = ae_loss + self.gamma * vae_loss

        if update:
            loss.backward()
            self.optimizer.step()
            return x

        else:
            tr_data = {}
            tr_data["loss"] = loss.item()
            tr_data["ae_loss"] = ae_loss.item()
            tr_data["vae_loss"] = vae_loss.item()

        return x, tr_data

# Cell


class RNN_IN_VAE(RNN_VAE):
    """
    inherit from RNN_VAE and add the GAN part
    """

    def __init__(self, device, args):
        # super(RNN_AE, self).__init__(device, args)
        RNN_VAE.__init__(self, device, args)
        # add extra parameters
        self.alpha = args.alpha
        self.beta = args.beta
        self.gamma = args.gamma
        self.m = args.m
        self.n_pretrain = args.n_pretrain

        enc_params = list(self.conv_part_enc.parameters(
        )) + list(self.fc_part_enc.parameters()) + list(self.transition.parameters())
        self.optimizerEnc = optim.Adam(enc_params, lr=args.lr)

        dec_params = list(self.conv_part_dec.parameters(
        )) + list(self.fc_part_dec.parameters()) + list(self.transition.parameters())
        self.optimizerDec = optim.Adam(dec_params, lr=args.lr)

    def forward(self, batch, update=True):

        # prepare
        self.optimizer.zero_grad()
        img = self.prep_input(batch)

        # (1st) Pass Original
        # --------------------------------------
        # encode
        z = self.encode(img)
        z, mu, log_sig2 = self.vae_sampling(z)

        # decode
        z = self.rnn_transition(z)
        x_re = self.decode(z)

        # Losses
        ae_loss = self.beta * self.mse_loss(img, x_re)
        kl_loss = self. gamma * self.kl_loss(mu, log_sig2)

        # (2nd) Pass Reconstruct Original (Enc)
        # --------------------------------------
        # encode
        z_re_1 = self.encode(x_re.detach())
        z_re_1, mu_re_1, log_sig2_re_1 = self.vae_sampling(z_re_1)

        # Losses
        kl_loss_re_e = self.kl_loss(mu_re_1, log_sig2_re_1)

        # (3rd) Pass Generate Fake imgs (Enc)
        # --------------------------------------
        # generate fake samples
        z_p = torch.randn_like(z, device=self.device)

        # decode
        z_p = self.rnn_transition(z_p)
        x_p = self.decode(z_p)

        # encode (xp stopped!)
        z_p_re_1 = self.encode(x_p.detach())
        z_p_re_1, mu_p_re_1, log_sig2_re_1 = self.vae_sampling(z_p_re_1)

        # Losses
        kl_loss_p_e = self.kl_loss(mu_p_re_1, log_sig2_re_1)

        # -------
        l_adv_e = self.alpha * \
            0.5 * (torch.clamp(self.m - kl_loss_re_e, min=0) +
                   torch.clamp(self.m - kl_loss_p_e, min=0))
        L_e = ae_loss + kl_loss + l_adv_e

        if update:
            L_e.backward(retain_graph=True)
            self.optimizerEnc.step()
        # ------

        # (4th) Pass Reconstruct Original (Dec)
        # --------------------------------------
        # encode (x_re free)
        z_re_2 = self.encode(x_re)
        z_re_2, mu_re_2, log_sig2_re_2 = self.vae_sampling(z_re_2)

        # Losses
        kl_loss_re_d = self.kl_loss(mu_re_2, log_sig2_re_2)

        # (5th) Pass Generate Fake imgs (Dec)
        # --------------------------------------
        # encode (xp free)
        z_p_re_2 = self.encode(x_p)
        z_p_re_2, mu_p_re_2, log_sig2_re_2 = self.vae_sampling(z_p_re_2)

        # Losses
        kl_loss_p_d = self.kl_loss(mu_p_re_1, log_sig2_re_1)

        L_d = self.alpha * 0.5 * (kl_loss_re_d + kl_loss_p_d)

        # ------
        if update:
            L_d.backward()
            self.optimizerDec.step()
            return x_re
        # ------

        else:
            tr_data = {}
            tr_data["L_encoder"] = L_e.item()
            tr_data["L_decoder"] = L_d.item() + ae_loss.item() + kl_loss.item()
            tr_data["ae_loss"] = ae_loss.item()
            tr_data["vae_loss"] = kl_loss.item()
            tr_data["l_adv_e"] = l_adv_e.item()
            tr_data["l_adv_d"] = L_d.item()

        return x_re, tr_data

# Cell


def Creator_RNN_AE(device, args):
    """
    return an instance of the class depending on the mode set in args
    """
    if args.rnn_vae:
        if args.rnn_intro:
            model = RNN_IN_VAE(device, args)
        else:
            model = RNN_VAE(device, args)
    else:
        model = RNN_AE(device, args)
    return model