{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> Utilities for tracking the experimental results and saving the parameter setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "# For storing and Documentation\n",
    "import datetime\n",
    "import json\n",
    "import datetime\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from statistics import mean\n",
    "\n",
    "# For Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "from scipy.ndimage.interpolation import affine_transform\n",
    "\n",
    "# Using tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# name of the logfile\n",
    "LOG = \"/_Log.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class Tracker(object):\n",
    "    \"\"\"\n",
    "    The Data tracker class serves as a uniform datatracker for all Modules\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args, log_view=True):\n",
    "        \"\"\"\n",
    "        Setup the Folders for tracking\n",
    "        \"\"\"\n",
    "        super(Tracker, self).__init__()\n",
    "        # general defines:\n",
    "        self.channels = len(args.perspectives)\n",
    "        self.dim = args.dim\n",
    "        \n",
    "        self.crop_size = args.crop_size\n",
    "        self.pic_size = args.pic_size\n",
    "        self.model_type = args.model_type\n",
    "        self.log_view = log_view\n",
    "        # Affine transform matrix.\n",
    "        self.T = np.array([[1, -1], [0, 1]])\n",
    "        # The results to track as empty dict:\n",
    "        self.tr_dict = {}\n",
    "        # create directory name\n",
    "        date = datetime.datetime.now()\n",
    "        self.dir_name = \"../data/%s %d-%d-%d at %d-%d\" % (\n",
    "            args.model_type,\n",
    "            date.year,\n",
    "            date.month,\n",
    "            date.day,\n",
    "            date.hour,\n",
    "            date.minute,\n",
    "        )\n",
    "        self.dataset = args.dataset_type\n",
    "\n",
    "        # internal counting for visualization\n",
    "        self.internal_count = 100\n",
    "        self.classes = args.classes\n",
    "        self.best_score = {}\n",
    "        self.best_score[\"all\"] = 0\n",
    "        for cl in self.classes:\n",
    "            self.best_score[cl] = 0\n",
    "        # store the path of the best model\n",
    "        self.model_path = self.dir_name + \"/_model\"\n",
    "        self.image_path = self.dir_name + \"/images\"\n",
    "\n",
    "        # repair for incorrect view\n",
    "        self.view_re_x = [1, len(args.perspectives), -1, args.pic_size, args.pic_size]\n",
    "\n",
    "        # Create new directory\n",
    "        try:\n",
    "            os.mkdir(self.dir_name)\n",
    "            os.mkdir(self.image_path)\n",
    "        except:\n",
    "            print(\n",
    "                \"\\nFoler: \"\n",
    "                + self.dir_name\n",
    "                + \" exists already.\\nFiles will be overwritten.\\n\"\n",
    "            )\n",
    "            open(self.dir_name + LOG, \"w\").close()\n",
    "\n",
    "        # Save set of hyperparameters\n",
    "        with open(self.dir_name + \"/_params.json\", \"w\") as f:\n",
    "            json.dump(args._get_kwargs(), f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    def view_3d(self, x, scale=0.7, alpha=1.0, bg_val=-1):\n",
    "        \"\"\"\n",
    "        Visualize the 3d pictures as expanded slideshow\n",
    "        args:\n",
    "            x: 3d matrix (img_h, img_w, img_z)\n",
    "            sclae: define the distance between slides\n",
    "            alpha: visibility\n",
    "            bg_val: background value\n",
    "        \"\"\"\n",
    "        # List of images instead 3d matrix\n",
    "        x = x.numpy()\n",
    "        images = [x[i, :, :] for i in range(self.crop_size)]\n",
    "\n",
    "        # Define size of new picture\n",
    "        stacked_height = 2 * self.pic_size\n",
    "        stacked_width = int(\n",
    "            self.pic_size + (self.crop_size - 1) * self.pic_size * scale\n",
    "        )\n",
    "        stacked = np.full((stacked_height, stacked_width), bg_val)\n",
    "\n",
    "        # Go over each slide\n",
    "        for i in range(self.crop_size):\n",
    "            # The first image will be right most and on the \"bottom\" of the stack.\n",
    "            o = (self.crop_size - i - 1) * self.pic_size * scale\n",
    "            out = affine_transform(\n",
    "                images[i][0, :, :],\n",
    "                self.T,\n",
    "                offset=[o, -o],\n",
    "                output_shape=stacked.shape,\n",
    "                cval=bg_val,\n",
    "            )\n",
    "            stacked[out != bg_val] = out[out != bg_val]\n",
    "\n",
    "        # plot the image series\n",
    "        plt.imshow(stacked, alpha=alpha, interpolation=\"nearest\", cmap=\"gray\")\n",
    "\n",
    "    def show(self, img):\n",
    "        \"\"\"subfunction for visualization\"\"\"\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation=\"nearest\")\n",
    "        \n",
    "    def draw_loss(self, tr_data):\n",
    "        \"\"\"track the losses as a pdf plot\"\"\"\n",
    "        # Go over all Losses and Plot\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        for k in tr_data.keys():\n",
    "            # Append / Create new\n",
    "            if k in self.tr_dict.keys():\n",
    "                self.tr_dict[k].append(tr_data[k])\n",
    "            else:\n",
    "                self.tr_dict[k] = [tr_data[k]]\n",
    "\n",
    "            # Plot the current progress in \"_Loss.png\"\n",
    "            plt.plot(self.tr_dict[k], label=k)\n",
    "\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.yscale(\"log\") if self.log_view else None\n",
    "        plt.grid(True, alpha=0.25)\n",
    "        plt.legend()\n",
    "        plt.savefig(self.dir_name + \"/_Losses.pdf\")\n",
    "        plt.close()\n",
    "        \n",
    "    def draw_mrnet(self, x, x_re, iteration):\n",
    "        \"\"\"draw an imagegrid for each channel\"\"\"\n",
    "        \n",
    "        for channel in range(self.channels):\n",
    "\n",
    "            # init view list\n",
    "            if self.dim == 3:\n",
    "\n",
    "                if len(x.shape) < 5:\n",
    "                    x = x.permute(1, 0, 2, 3)\n",
    "                    x = x.reshape(self.view_re_x)\n",
    "\n",
    "                if len(x_re.shape) < 5:\n",
    "                    x_re = x_re.permute(1, 0, 2, 3)\n",
    "                    x_re = x_re.reshape(self.view_re_x)\n",
    "\n",
    "                real_pic = x[0, channel, :, :, :].view(\n",
    "                    (self.crop_size, -1, self.pic_size, self.pic_size)\n",
    "                )\n",
    "\n",
    "                fake_pic = x_re[0, channel, :, :, :].view(\n",
    "                    (self.crop_size, -1, self.pic_size, self.pic_size)\n",
    "                )\n",
    "\n",
    "                # add the 3d visualization\n",
    "                plt.figure(figsize=(24, 12))\n",
    "                plt.subplot(2, 1, 1)\n",
    "                self.view_3d(real_pic)\n",
    "                plt.subplot(2, 1, 2)\n",
    "                self.view_3d(fake_pic)\n",
    "                plt.savefig(\n",
    "                    self.image_path\n",
    "                    + \"/rec_iteration_%d_class_%d_3d_view.png\"\n",
    "                    % (iteration, channel)\n",
    "                )\n",
    "                plt.close()\n",
    "                \n",
    "            else:\n",
    "                real_pic = x[0, channel, :, :].view(\n",
    "                    (self.crop_size, -1, self.pic_size, self.pic_size)\n",
    "                )\n",
    "                fake_pic = x_re[0, channel, :, :].view(\n",
    "                    (self.crop_size, -1, self.pic_size, self.pic_size)\n",
    "                )\n",
    "\n",
    "            # plot in figure\n",
    "            plt.figure(channel, figsize=(24, 24))\n",
    "            if iteration == 0:\n",
    "                self.show(\n",
    "                    vutils.make_grid(real_pic, nrow=4, padding=2, normalize=True)\n",
    "                )\n",
    "                plt.savefig(self.image_path + \"/class_%d__original.jpg\" % (channel))\n",
    "            else:\n",
    "                self.show(\n",
    "                    vutils.make_grid(fake_pic, nrow=4, padding=2, normalize=True)\n",
    "                )\n",
    "                plt.savefig(\n",
    "                    self.image_path\n",
    "                    + \"/rec_iteration_%d_class_%d.jpg\" % (iteration, channel)\n",
    "                )\n",
    "                plt.savefig(self.dir_name + \"/current.jpg\")\n",
    "            plt.close()\n",
    "            \n",
    "    def draw_kneexray(self, x, x_re, iteration):\n",
    "        \"\"\"simple plot drawing the current picture\"\"\"\n",
    "        # plot in figure\n",
    "        plt.figure(1337, figsize=(24, 24))\n",
    "        if iteration == 0:\n",
    "            self.show(\n",
    "                vutils.make_grid(x[0, :, :, :], nrow=4, padding=2, normalize=True)\n",
    "            )\n",
    "            plt.savefig(self.image_path + \"/original.jpg\")\n",
    "        else:\n",
    "            self.show(\n",
    "                vutils.make_grid(\n",
    "                    x_re[0, :, :, :], nrow=4, padding=2, normalize=True\n",
    "                )\n",
    "            )\n",
    "            plt.savefig(self.image_path + f\"/rec_iteration_{iteration}.jpg\")\n",
    "            plt.savefig(self.dir_name + \"/current.jpg\")\n",
    "        plt.close()\n",
    "    \n",
    "    def track_progress(self, model, data, iteration):\n",
    "        \"\"\"\n",
    "        Visualize the Progress by applying the validation loader and visualizing the results\n",
    "        \"\"\"\n",
    "        # Get the original image\n",
    "        x = model.prep(data).detach().cpu()\n",
    "\n",
    "        # Get the current results:\n",
    "        x_re, tr_data = model(data, update=False)\n",
    "        x_re = x_re.detach().cpu()\n",
    "\n",
    "        self.draw_loss(tr_data)\n",
    "\n",
    "        # write to \"_Log.txt\" file\n",
    "        with open(self.dir_name + LOG, \"a\") as file:\n",
    "            file.write(\"\\n\\nIteration: %d\" % (iteration))\n",
    "            for k in tr_data.keys():\n",
    "                file.write(\"\\n%s: %.4f\" % (k, tr_data[k]))\n",
    "\n",
    "        # Save the losses as npy\n",
    "        np.save(self.dir_name + \"/_Losses.npy\", self.tr_dict)\n",
    "\n",
    "        # save the current model:\n",
    "        torch.save(model.state_dict(), self.dir_name + \"/_model\")\n",
    "\n",
    "        # Plot Results:\n",
    "        if self.dataset == \"MRNet\":\n",
    "            self.draw_mrnet(x, x_re, iteration)\n",
    "            \n",
    "        else:\n",
    "            self.draw_kneexray(x, x_re, iteration)\n",
    "            \n",
    "\n",
    "    def update_network(self, cl, model, score):\n",
    "        \"\"\"\n",
    "        update the network if the score is lower\n",
    "        \"\"\"\n",
    "        if self.best_score[cl] < score:\n",
    "            print(\"\\n\\n  ---Best Score %s %.4f---- \\n\" % (cl, score))\n",
    "            # delete old model if it exists\n",
    "            if self.best_score[cl] > 0:\n",
    "                os.remove(self.model_path + \"_%s_%.4f\" % (cl, self.best_score[cl]))\n",
    "            # save new model\n",
    "            torch.save(\n",
    "                model.state_dict(), self.model_path + \"_%s_%.4f\" % (cl, score)\n",
    "            )\n",
    "            # reset score\n",
    "            self.best_score[cl] = score\n",
    "\n",
    "    def get_accuracy(self, model, valid_loader, iteration):\n",
    "        \"\"\"\n",
    "        Go trough the whole validation dataset and determine accuracy\n",
    "        \"\"\"\n",
    "        # predefine\n",
    "        preds = {}\n",
    "        labels = {}\n",
    "        for cl in self.classes:\n",
    "            preds[cl] = []\n",
    "            labels[cl] = []\n",
    "\n",
    "        # calculate accuracy\n",
    "        for data in valid_loader:\n",
    "            pred, label, _ = model.forward(data, update=False)\n",
    "            # get the current output\n",
    "            pred = pred.data.cpu().numpy()\n",
    "            label = label.data.cpu().numpy()\n",
    "            # append predictions\n",
    "            for i, cl in enumerate(self.classes):\n",
    "                preds[cl].append(pred[i])\n",
    "                labels[cl].append(label[i])\n",
    "\n",
    "        # get the accuracies\n",
    "        acc = {}\n",
    "        for cl in self.classes:\n",
    "            fpr, tpr, _ = metrics.roc_curve(labels[cl], preds[cl])\n",
    "            loc_acc = metrics.auc(fpr, tpr)\n",
    "            pred_label = [1 if pre > 0.5 else 0 for pre in preds[cl]]\n",
    "            acc[cl] = accuracy_score(labels[cl], pred_label)\n",
    "            \n",
    "            # plot the roc curve\n",
    "            plot_roc_curve(fpr, tpr, loc_acc, cl, lw=2)\n",
    "            plt.savefig(f'{self.dir_name}/images/{iteration}_{cl}_roc.png')\n",
    "            plt.close()\n",
    "            \n",
    "            # plot the confusion matrix\n",
    "            conf = confusion_matrix(labels[cl], pred_label)\n",
    "            plot_confusion_matrix(conf, [f'{cl}', 'healthy'])\n",
    "            plt.savefig(f'{self.dir_name}/images/{iteration}_{cl}_cm.png')\n",
    "            plt.close()\n",
    "            \n",
    "\n",
    "        acc[\"all\"] = mean([acc[cl] for cl in self.classes])\n",
    "\n",
    "        if \"acc_all\" in self.tr_dict.keys():\n",
    "            for cl in acc.keys():\n",
    "                self.tr_dict[\"acc_%s\" % (cl)].append(acc[cl])\n",
    "        else:\n",
    "            for cl in acc.keys():\n",
    "                self.tr_dict[\"acc_%s\" % (cl)] = [acc[cl]]\n",
    "\n",
    "        # plot result\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        for k in self.tr_dict.keys():\n",
    "            # Plot the current progress in \"_Loss.png\"\n",
    "            plt.plot(self.tr_dict[k], label=k)\n",
    "\n",
    "        # format plot\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.grid(True, alpha=0.25)\n",
    "        plt.legend()\n",
    "        plt.savefig(self.dir_name + \"/_Losses.pdf\")\n",
    "        plt.close()\n",
    "\n",
    "        # write to \"_Log.txt\" file\n",
    "        with open(self.dir_name + LOG, \"a\") as file:\n",
    "            file.write(\"\\n\\nIteration: %d\" % (iteration))\n",
    "            for k in self.tr_dict.keys():\n",
    "                file.write(\"\\n%s: %.4f\" % (k, self.tr_dict[k][-1]))\n",
    "\n",
    "        # Save the losses as npy\n",
    "        np.save(self.dir_name + \"/_Losses.npy\", self.tr_dict)\n",
    "\n",
    "        # save the best performing networks\n",
    "        for cl in acc.keys():\n",
    "            self.update_network(cl, model, acc[cl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix\n",
    "from fastai.metrics import error_rate, accuracy, roc_curve, AUROC\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, auc, name, lw=2, show=False):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.grid(0.25)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver operating characteristic for {name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show() if show else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "    cm, target_names, title=\"Confusion matrix\", cmap=None, normalize=False, show=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap(\"Blues\")\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(\n",
    "                j,\n",
    "                i,\n",
    "                \"{:0.4f}\".format(cm[i, j]),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "            )\n",
    "        else:\n",
    "            plt.text(\n",
    "                j,\n",
    "                i,\n",
    "                \"{:,}\".format(cm[i, j]),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\n",
    "        \"Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}\".format(\n",
    "            accuracy, misclass)\n",
    "    )\n",
    "    plt.show() if show else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dataloader.ipynb.\n",
      "Converted 01_architecture.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_parameters.ipynb.\n",
      "Converted 04_train_loop.ipynb.\n",
      "Converted 05_abstract_model.ipynb.\n",
      "Converted 10_diagnosis.ipynb.\n",
      "Converted 20_dcgan.ipynb.\n",
      "Converted 21_introvae.ipynb.\n",
      "Converted 22_vqvae.ipynb.\n",
      "Converted 23_bigan.ipynb.\n",
      "Converted 24_mocoae.ipynb.\n",
      "Converted 33_rnn_vae.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
