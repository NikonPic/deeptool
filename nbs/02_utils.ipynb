{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> Utilities for tracking the experimental results and saving the parameter setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "# For storing and Documentation\n",
    "import datetime\n",
    "import json\n",
    "import datetime\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from statistics import mean\n",
    "\n",
    "# For Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "from scipy.ndimage.interpolation import affine_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class Tracker(object):\n",
    "    \"\"\"\n",
    "    The Data tracker class serves as a uniform datatracker for all Modules\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args, log_view=True):\n",
    "        \"\"\"\n",
    "        Setup the Folders for tracking\n",
    "        \"\"\"\n",
    "        super(Tracker, self).__init__()\n",
    "        # general defines:\n",
    "        self.channels = len(args.perspectives)\n",
    "        self.dim = args.dim\n",
    "        self.crop_size = args.crop_size\n",
    "        self.pic_size = args.pic_size\n",
    "        self.model_type = args.model_type\n",
    "        self.log_view = log_view\n",
    "        # Affine transform matrix.\n",
    "        self.T = np.array([[1, -1], [0, 1]])\n",
    "        # The results to track as empty dict:\n",
    "        self.tr_dict = {}\n",
    "        # create directory name\n",
    "        date = datetime.datetime.now()\n",
    "        self.dir_name = \"../data/%s %d-%d-%d at %d-%d\" % (\n",
    "            args.model_type,\n",
    "            date.year,\n",
    "            date.month,\n",
    "            date.day,\n",
    "            date.hour,\n",
    "            date.minute,\n",
    "        )\n",
    "        self.dataset = args.dataset_type\n",
    "\n",
    "        # internal counting for visualization\n",
    "        self.internal_count = 100\n",
    "        self.classes = args.classes\n",
    "        self.best_score = {}\n",
    "        self.best_score[\"all\"] = 1e8\n",
    "        for cl in self.classes:\n",
    "            self.best_score[cl] = 1e8\n",
    "        # store the path of the best model\n",
    "        self.model_path = self.dir_name + \"/_model\"\n",
    "\n",
    "        # repair for incorrect view\n",
    "        self.view_re_x = [1, len(args.perspectives), -1, args.pic_size, args.pic_size]\n",
    "\n",
    "        # Create new directory\n",
    "        try:\n",
    "            os.mkdir(self.dir_name)\n",
    "        except:\n",
    "            print(\n",
    "                \"\\nFoler: \"\n",
    "                + self.dir_name\n",
    "                + \" exists already.\\nFiles will be overwritten.\\n\"\n",
    "            )\n",
    "            open(self.dir_name + \"\\_Log.txt\", \"w\").close()\n",
    "\n",
    "        # Save set of hyperparameters\n",
    "        with open(self.dir_name + \"/_params.json\", \"w\") as f:\n",
    "            json.dump(args._get_kwargs(), f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    def view_3d(self, x, scale=0.7, alpha=1.0, bg_val=-1):\n",
    "        \"\"\"\n",
    "        Visualize the 3d pictures as expanded slideshow\n",
    "        args:\n",
    "            x: 3d matrix (img_h, img_w, img_z)\n",
    "            sclae: define the distance between slides\n",
    "            alpha: visibility\n",
    "            bg_val: background value\n",
    "        \"\"\"\n",
    "        # List of images instead 3d matrix\n",
    "        x = x.numpy()\n",
    "        images = [x[i, :, :] for i in range(self.crop_size)]\n",
    "\n",
    "        # Define size of new picture\n",
    "        stacked_height = 2 * self.pic_size\n",
    "        stacked_width = int(\n",
    "            self.pic_size + (self.crop_size - 1) * self.pic_size * scale\n",
    "        )\n",
    "        stacked = np.full((stacked_height, stacked_width), bg_val)\n",
    "\n",
    "        # Go over each slide\n",
    "        for i in range(self.crop_size):\n",
    "            # The first image will be right most and on the \"bottom\" of the stack.\n",
    "            o = (self.crop_size - i - 1) * self.pic_size * scale\n",
    "            out = affine_transform(\n",
    "                images[i][0, :, :],\n",
    "                self.T,\n",
    "                offset=[o, -o],\n",
    "                output_shape=stacked.shape,\n",
    "                cval=bg_val,\n",
    "            )\n",
    "            stacked[out != bg_val] = out[out != bg_val]\n",
    "\n",
    "        # plot the image series\n",
    "        plt.imshow(stacked, alpha=alpha, interpolation=\"nearest\", cmap=\"gray\")\n",
    "\n",
    "    def show(self, img):\n",
    "        \"\"\"subfunction for visualization\"\"\"\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation=\"nearest\")\n",
    "\n",
    "    def track_progress(self, model, data, iteration):\n",
    "        \"\"\"\n",
    "        Visualize the Progress by applying the validation loader and visualizing the results\n",
    "        \"\"\"\n",
    "        # Get the original image\n",
    "        x = model.prep(data).detach().cpu()\n",
    "\n",
    "        # Get the current results:\n",
    "        x_re, tr_data = model(data, update=False)\n",
    "        x_re = x_re.detach().cpu()\n",
    "\n",
    "        # Go over all Losses and Plot\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        for k in tr_data.keys():\n",
    "            # Append / Create new\n",
    "            if k in self.tr_dict.keys():\n",
    "                self.tr_dict[k].append(tr_data[k])\n",
    "            else:\n",
    "                self.tr_dict[k] = [tr_data[k]]\n",
    "\n",
    "            # Plot the current progress in \"_Loss.png\"\n",
    "            plt.plot(self.tr_dict[k], label=k)\n",
    "\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.yscale(\"log\") if self.log_view else None\n",
    "        plt.grid(True, alpha=0.25)\n",
    "        plt.legend()\n",
    "        plt.savefig(self.dir_name + \"/_Losses.pdf\")\n",
    "        plt.close()\n",
    "\n",
    "        # write to \"_Log.txt\" file\n",
    "        with open(self.dir_name + \"/_Log.txt\", \"a\") as file:\n",
    "            file.write(\"\\n\\nIteration: %d\" % (iteration))\n",
    "            for k in tr_data.keys():\n",
    "                file.write(\"\\n%s: %.4f\" % (k, tr_data[k]))\n",
    "\n",
    "        # Save the losses as npy\n",
    "        np.save(self.dir_name + \"/_Losses.npy\", self.tr_dict)\n",
    "\n",
    "        # save the current model:\n",
    "        torch.save(model.state_dict(), self.dir_name + \"/_model\")\n",
    "\n",
    "        # Plot Results:\n",
    "        if (\n",
    "            self.model_type not in (\"diagnosis\")\n",
    "            and self.internal_count > 2\n",
    "            and self.dataset == \"MRNet\"\n",
    "        ):\n",
    "            self.internal_count = 0\n",
    "\n",
    "            for channel in range(self.channels):\n",
    "                # init view list\n",
    "                if self.dim == 3:\n",
    "\n",
    "                    if len(x.shape) < 5:\n",
    "                        x = x.permute(1, 0, 2, 3)\n",
    "                        x = x.reshape(self.view_re_x)\n",
    "\n",
    "                    if len(x_re.shape) < 5:\n",
    "                        x_re = x_re.permute(1, 0, 2, 3)\n",
    "                        x_re = x_re.reshape(self.view_re_x)\n",
    "\n",
    "                    real_pic = x[0, channel, :, :, :].view(\n",
    "                        (self.crop_size, -1, self.pic_size, self.pic_size)\n",
    "                    )\n",
    "\n",
    "                    fake_pic = x_re[0, channel, :, :, :].view(\n",
    "                        (self.crop_size, -1, self.pic_size, self.pic_size)\n",
    "                    )\n",
    "\n",
    "                    # add the 3d visualization\n",
    "                    plt.figure(figsize=(24, 12))\n",
    "                    plt.subplot(2, 1, 1)\n",
    "                    self.view_3d(real_pic)\n",
    "                    plt.subplot(2, 1, 2)\n",
    "                    self.view_3d(fake_pic)\n",
    "                    plt.savefig(\n",
    "                        self.dir_name\n",
    "                        + \"/rec_iteration_%d_class_%d_3d_view.png\"\n",
    "                        % (iteration, channel)\n",
    "                    )\n",
    "                    plt.close()\n",
    "\n",
    "                else:\n",
    "                    real_pic = x[0, channel, :, :].view(\n",
    "                        (self.crop_size, -1, self.pic_size, self.pic_size)\n",
    "                    )\n",
    "                    fake_pic = x_re[0, channel, :, :].view(\n",
    "                        (self.crop_size, -1, self.pic_size, self.pic_size)\n",
    "                    )\n",
    "\n",
    "                # plot in figure\n",
    "                plt.figure(channel, figsize=(24, 24))\n",
    "                if iteration == 0:\n",
    "                    self.show(\n",
    "                        vutils.make_grid(real_pic, nrow=4, padding=2, normalize=True)\n",
    "                    )\n",
    "                    plt.savefig(self.dir_name + \"/class_%d__original.jpg\" % (channel))\n",
    "                else:\n",
    "                    self.show(\n",
    "                        vutils.make_grid(fake_pic, nrow=4, padding=2, normalize=True)\n",
    "                    )\n",
    "                    plt.savefig(\n",
    "                        self.dir_name\n",
    "                        + \"/rec_iteration_%d_class_%d.jpg\" % (iteration, channel)\n",
    "                    )\n",
    "                plt.close()\n",
    "\n",
    "        else:\n",
    "            # plot in figure\n",
    "            plt.figure(1337, figsize=(24, 24))\n",
    "            if iteration == 0:\n",
    "                self.show(\n",
    "                    vutils.make_grid(x[0, :, :, :], nrow=4, padding=2, normalize=True)\n",
    "                )\n",
    "                plt.savefig(self.dir_name + \"/original.jpg\")\n",
    "            else:\n",
    "                self.show(\n",
    "                    vutils.make_grid(\n",
    "                        x_re[0, :, :, :], nrow=4, padding=2, normalize=True\n",
    "                    )\n",
    "                )\n",
    "                plt.savefig(self.dir_name + f\"/rec_iteration_{iteration}.jpg\")\n",
    "                plt.savefig(self.dir_name + \"/current.jpg\")\n",
    "            plt.close()\n",
    "\n",
    "        # increase the counter\n",
    "        self.internal_count += 1\n",
    "\n",
    "    def update_network(self, cl, model, score):\n",
    "        \"\"\"\n",
    "        update the network if the score is lower\n",
    "        \"\"\"\n",
    "        if self.best_score[cl] > score:\n",
    "            print(\"\\n\\n  ---Best Score %s %.4f---- \\n\" % (cl, 1 - score))\n",
    "            # delete old model if it exists\n",
    "            if self.best_score[cl] < 1:\n",
    "                os.remove(self.model_path + \"_%s_%.4f\" % (cl, 1 - self.best_score[cl]))\n",
    "            # save new model\n",
    "            torch.save(\n",
    "                model.state_dict(), self.model_path + \"_%s_%.4f\" % (cl, 1 - score)\n",
    "            )\n",
    "            # reset score\n",
    "            self.best_score[cl] = score\n",
    "\n",
    "    def get_accuracy(self, model, valid_loader, iteration):\n",
    "        \"\"\"\n",
    "        Go trough the whole validation dataset and determine accuracy\n",
    "        \"\"\"\n",
    "        # predefine\n",
    "        count = 0\n",
    "        loss = 0\n",
    "        preds = {}\n",
    "        labels = {}\n",
    "        for cl in self.classes:\n",
    "            preds[cl] = []\n",
    "            labels[cl] = []\n",
    "\n",
    "        # calculate accuracy\n",
    "        for data in valid_loader:\n",
    "            pred, label, tr_data = model.forward(data, update=False)\n",
    "            # get the current output\n",
    "            pred = pred.data.cpu().numpy()\n",
    "            label = label.data.cpu().numpy()\n",
    "            # append predictions\n",
    "            for i, cl in enumerate(self.classes):\n",
    "                preds[cl].append(pred[i])\n",
    "                labels[cl].append(label[i])\n",
    "\n",
    "            loss += tr_data[\"loss\"]\n",
    "            count += 1\n",
    "\n",
    "        # get the accuracies\n",
    "        acc = {}\n",
    "        for cl in self.classes:\n",
    "            fpr, tpr, _ = metrics.roc_curve(labels[cl], preds[cl])\n",
    "            acc[cl] = 1 - metrics.auc(fpr, tpr)\n",
    "\n",
    "        acc[\"all\"] = mean([acc[cl] for cl in self.classes])\n",
    "\n",
    "        loss /= count\n",
    "\n",
    "        if \"err_all\" in self.tr_dict.keys():\n",
    "            for cl in acc.keys():\n",
    "                self.tr_dict[\"err_%s\" % (cl)].append(acc[cl])\n",
    "        else:\n",
    "            for cl in acc.keys():\n",
    "                self.tr_dict[\"err_%s\" % (cl)] = [acc[cl]]\n",
    "\n",
    "        # plot result\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        for k in self.tr_dict.keys():\n",
    "            # Plot the current progress in \"_Loss.png\"\n",
    "            plt.plot(self.tr_dict[k], label=k)\n",
    "\n",
    "        # format plot\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.grid(True, alpha=0.25)\n",
    "        plt.legend()\n",
    "        plt.savefig(self.dir_name + \"/_Losses.pdf\")\n",
    "        plt.close()\n",
    "\n",
    "        # write to \"_Log.txt\" file\n",
    "        with open(self.dir_name + \"/_Log.txt\", \"a\") as file:\n",
    "            file.write(\"\\n\\nIteration: %d\" % (iteration))\n",
    "            for k in self.tr_dict.keys():\n",
    "                file.write(\"\\n%s: %.4f\" % (k, self.tr_dict[k][-1]))\n",
    "\n",
    "        # Save the losses as npy\n",
    "        np.save(self.dir_name + \"/_Losses.npy\", self.tr_dict)\n",
    "\n",
    "        # save the best performing networks\n",
    "        for cl in acc.keys():\n",
    "            self.update_network(cl, model, acc[cl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dataloader.ipynb.\n",
      "Converted 01_architecture.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_parameters.ipynb.\n",
      "Converted 04_train_loop.ipynb.\n",
      "Converted 05_abstract_model.ipynb.\n",
      "Converted 10_diagnosis.ipynb.\n",
      "Converted 20_dcgan.ipynb.\n",
      "Converted 21_introvae.ipynb.\n",
      "Converted 22_vqvae.ipynb.\n",
      "Converted 23_bigan.ipynb.\n",
      "Converted 24_mocoae.ipynb.\n",
      "Converted 33_rnn_vae.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
