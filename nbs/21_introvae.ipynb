{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model.introvae\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro VAE\n",
    "\n",
    "> Structure of the Hybrid Autoencoder - GAN Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/introvae.png\" alt=\"Drawing\" style=\"width: 900px;\"/>\n",
    "     \n",
    "https://arxiv.org/pdf/1807.06358.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from deeptool.architecture import Encoder, Decoder\n",
    "from deeptool.abs_model import AbsModel\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class IntroVAE(AbsModel):\n",
    "    \"\"\"\n",
    "    Modification of the IntroVAE-Paper for 3-Dimensional tasks in MR-Imaging\n",
    "    based on: https://arxiv.org/abs/1807.06358\n",
    "    modified from: https://github.com/woxuankai/IntroVAE-Pytorch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device, args):\n",
    "        \"\"\"\n",
    "        Setup the general architecture for the IntroVAE model, composed of:\n",
    "        >Encoder, Decoder<\n",
    "        \"\"\"\n",
    "        super(IntroVAE, self).__init__(args)\n",
    "        # gpu / cpu\n",
    "        self.device = device\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(args).to(self.device)\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(args).to(self.device)\n",
    "\n",
    "        # add further training params here...\n",
    "        self.alpha = 0  # GAN\n",
    "        self.beta = args.beta  # AE\n",
    "        self.gamma = args.gamma  # VAE\n",
    "        self.m = args.m  # margin for stopping gae learning if too far apart\n",
    "\n",
    "        # without mean -> squarred error\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "        self.bce_loss = nn.BCELoss(reduction=\"sum\")\n",
    "\n",
    "        # optimizers\n",
    "        self.optimizerEnc = optim.Adam(self.encoder.parameters(), lr=args.lr)\n",
    "        self.optimizerDec = optim.Adam(self.decoder.parameters(), lr=args.lr)\n",
    "\n",
    "    def reparametrisation(self, mu, log_sig2):\n",
    "        \"\"\"Apply the reparametrisation trick for VAE.\"\"\"\n",
    "\n",
    "        eps = torch.rand_like(mu, device=self.device)  # uniform distributed matrix\n",
    "        # mean + sigma * eps\n",
    "        z_latent = mu + torch.exp(torch.mul(0.5, log_sig2)) * eps\n",
    "        return z_latent\n",
    "\n",
    "    def kl_loss(self, mu, log_sig2):\n",
    "        \"\"\"\n",
    "        KL-Divergence between two univariate gaussian distributions\n",
    "        special case: compared to uniform distribution: mu2 = 0, sig2= 1\n",
    "        \"\"\"\n",
    "        return -0.5 * torch.sum(1 - torch.pow(mu, 2) - torch.exp(log_sig2) + log_sig2)\n",
    "\n",
    "    def ae_loss(self, x_hat, x):\n",
    "        \"\"\"\n",
    "        sqrt(sum_i sum_j (x_ij - x_hat_ij)^2)\n",
    "        pixelwise mean squared error! (sum requires to sum over one picture and the mean!)\n",
    "        \"\"\"\n",
    "        return self.mse_loss(x_hat, x)\n",
    "\n",
    "    def set_parameters(self, args):\n",
    "        \"\"\"\n",
    "        Control training by setting the parameters:\n",
    "        alpha, beta, gamma, m\n",
    "        \"\"\"\n",
    "        self.alpha = args.alpha\n",
    "        self.beta = args.beta\n",
    "        self.gamma = args.gamma\n",
    "        self.m = args.m\n",
    "    \n",
    "    def forward(self, data, update=True):\n",
    "        \"\"\"\n",
    "        Get the different relevant outputs for Intro VAE training\n",
    "        update=True to allow updating, update=False to keep networs constant\n",
    "        return x_re (reconstructed)\n",
    "        \"\"\"\n",
    "        # get the data\n",
    "        x = self.prep(data).to(self.device)\n",
    "        \n",
    "        #=========== Update E ================\n",
    "        self.optimizerEnc.zero_grad()\n",
    "        \n",
    "        # real\n",
    "        z_mu, z_log_sig2 = self.encoder(x)\n",
    "        z_enc = self.reparametrisation(z_mu, z_log_sig2)\n",
    "        x_re = self.decoder(z_enc)\n",
    "        \n",
    "        # fake\n",
    "        noise = torch.randn_like(z_enc, device=self.device)\n",
    "        fake = self.decoder(noise)\n",
    "        \n",
    "        # encode again\n",
    "        z_mu_re, z_log_sig2_re = self.encoder(x_re.detach())\n",
    "        z_mu_fake, z_log_sig2_fake = self.encoder(fake.detach())\n",
    "        \n",
    "        # get losses\n",
    "        loss_rec = self.ae_loss(x, x_re)\n",
    "        loss_e_real_kl = self.kl_loss(z_mu, z_log_sig2)\n",
    "        loss_e_rec_kl = self.kl_loss(z_mu_re, z_log_sig2_re)\n",
    "        loss_e_fake_kl = self.kl_loss(z_mu_fake, z_log_sig2_fake)\n",
    "        \n",
    "        # combine losses\n",
    "        loss_margin_e = loss_e_real_kl + (F.relu(self.m - loss_e_rec_kl) + F.relu(self.m - loss_e_fake_kl)) * self.alpha\n",
    "        loss_e = loss_rec * self.beta + loss_margin_e * self.gamma\n",
    "        \n",
    "        if update:\n",
    "            loss_e.backward()\n",
    "            self.optimizerEnc.step()\n",
    "        \n",
    "        #========= Update G ================== \n",
    "        self.optimizerDec.zero_grad()\n",
    "        \n",
    "        # real\n",
    "        z_mu, z_log_sig2 = self.encoder(x)\n",
    "        z_enc = self.reparametrisation(z_mu, z_log_sig2)\n",
    "        x_re = self.decoder(z_enc)\n",
    "        \n",
    "        # fake\n",
    "        noise = torch.randn_like(z_enc, device=self.device)\n",
    "        fake = self.decoder(noise)\n",
    "        \n",
    "        # encode again\n",
    "        z_mu_re, z_log_sig2_re = self.encoder(x_re)\n",
    "        z_mu_fake, z_log_sig2_fake = self.encoder(fake)\n",
    "        \n",
    "        # get losses\n",
    "        loss_rec = self.ae_loss(x, x_re)\n",
    "        loss_g_real_kl = self.kl_loss(z_mu, z_log_sig2)\n",
    "        loss_g_rec_kl = self.kl_loss(z_mu_re, z_log_sig2_re)\n",
    "        loss_g_fake_kl = self.kl_loss(z_mu_fake, z_log_sig2_fake)\n",
    "        \n",
    "        # combine losses\n",
    "        loss_margin_g = loss_g_real_kl * (loss_g_rec_kl + loss_g_fake_kl) * self.alpha\n",
    "        loss_g = loss_rec * self.beta + loss_margin_g * self.gamma\n",
    "        \n",
    "        if update:\n",
    "            loss_g.backward()\n",
    "            self.optimizerDec.step()\n",
    "        \n",
    "        else:\n",
    "            # setup dictionary for Tracking\n",
    "            tr_data = {}\n",
    "            tr_data[\"loss_rec\"] = loss_rec.item()\n",
    "            tr_data[\"loss_e_real_kl\"] = loss_e_real_kl.item()\n",
    "            tr_data[\"loss_margin_e\"] = loss_margin_e.item()\n",
    "            tr_data[\"loss_margin_g\"] = loss_margin_g.item()\n",
    "            tr_data[\"loss_e\"] = loss_e.item()\n",
    "            tr_data[\"loss_g\"] = loss_g.item()\n",
    "\n",
    "            # Return output and tracking data\n",
    "            return x_re, tr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from deeptool.train_loop import test_one_batch\n",
    "from deeptool.parameters import get_all_args, compat_args\n",
    "\n",
    "args = get_all_args()\n",
    "args.pic_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-Type: introvae\n"
     ]
    }
   ],
   "source": [
    "# 3 dim test\n",
    "args.model_type = \"introvae\"\n",
    "args.dim = 3\n",
    "args = compat_args(args)\n",
    "test_one_batch(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-Type: introvae\n"
     ]
    }
   ],
   "source": [
    "# 2 dim test\n",
    "args.dim = 2\n",
    "args = compat_args(args)\n",
    "test_one_batch(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dataloader.ipynb.\n",
      "Converted 01_architecture.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_parameters.ipynb.\n",
      "Converted 04_train_loop.ipynb.\n",
      "Converted 05_abstract_model.ipynb.\n",
      "Converted 10_diagnosis.ipynb.\n",
      "Converted 20_dcgan.ipynb.\n",
      "Converted 21_introvae.ipynb.\n",
      "Converted 22_vqvae.ipynb.\n",
      "Converted 23_bigan.ipynb.\n",
      "Converted 24_mocoae.ipynb.\n",
      "Converted 33_rnn_vae.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
