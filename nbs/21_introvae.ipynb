{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model.introvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro VAE\n",
    "\n",
    "> Structure of the Hybrid Autoencoder - GAN Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/introvae.png\" alt=\"Drawing\" style=\"width: 900px;\"/>\n",
    "     \n",
    "https://arxiv.org/pdf/1807.06358.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from deeptool.architecture import Encoder, Decoder\n",
    "from deeptool.utils import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class IntroVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Modification of the IntroVAE-Paper for 3-Dimensional tasks in MR-Imaging\n",
    "    based on: https://arxiv.org/abs/1807.06358\n",
    "    modified from: https://github.com/woxuankai/IntroVAE-Pytorch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device, args):\n",
    "        \"\"\"\n",
    "        Setup the general architecture for the IntroVAE model, composed of:\n",
    "        >Encoder, Decoder<\n",
    "        \"\"\"\n",
    "        super(IntroVAE, self).__init__()\n",
    "        # gpu / cpu\n",
    "        self.device = device\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(args).to(self.device)\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(args).to(self.device)\n",
    "\n",
    "        # add further training params here...\n",
    "        self.alpha = 0  # GAN\n",
    "        self.beta = args.beta  # AE\n",
    "        self.gamma = args.gamma  # VAE\n",
    "        self.m = args.m  # margin for stopping gae learning if too far apart\n",
    "\n",
    "        # without mean -> squarred error\n",
    "        self.mse_loss = nn.MSELoss(reduction='sum')\n",
    "        self.bce_loss = nn.BCELoss(reduction='sum')\n",
    "\n",
    "        # optimizers\n",
    "        self.optimizerEnc = optim.Adam(self.encoder.parameters(), lr=args.lr)\n",
    "        self.optimizerDec = optim.Adam(self.decoder.parameters(), lr=args.lr)\n",
    "\n",
    "        # Setup the tracker to visualize the progress\n",
    "        if args.track:\n",
    "            self.tracker = Tracker(args)\n",
    "\n",
    "    def watch_progress(self, test_data, iteration):\n",
    "        \"\"\"\n",
    "        Outsourced to Tracker\n",
    "        \"\"\"\n",
    "        self.tracker.track_progress(self, test_data, iteration)\n",
    "\n",
    "    def reparametrisation(self, mu, log_sig2):\n",
    "        \"\"\"Apply the reparametrisation trick for VAE.\"\"\"\n",
    "\n",
    "        eps = torch.rand_like(\n",
    "            mu, device=self.device)  # uniform distributed matrix\n",
    "        # mean + sigma * eps\n",
    "        z_latent = mu + torch.exp(torch.mul(0.5, log_sig2)) * eps\n",
    "        return z_latent\n",
    "\n",
    "    def kl_loss(self, mu, log_sig2):\n",
    "        \"\"\"\n",
    "        KL-Divergence between two univariate gaussian distributions\n",
    "        special case: compared to uniform distribution: mu2 = 0, sig2= 1\n",
    "        \"\"\"\n",
    "        return -0.5 * torch.sum(1 - torch.pow(mu, 2) - torch.exp(log_sig2) + log_sig2)\n",
    "\n",
    "    def ae_loss(self, x_hat, x):\n",
    "        \"\"\"\n",
    "        sqrt(sum_i sum_j (x_ij - x_hat_ij)^2)\n",
    "        pixelwise mean squared error! (sum requires to sum over one picture and the mean!)\n",
    "        \"\"\"\n",
    "        return self.mse_loss(x_hat, x).mean()\n",
    "\n",
    "    def set_parameters(self, args):\n",
    "        \"\"\"\n",
    "        Control training by setting the parameters:\n",
    "        alpha, beta, gamma, m\n",
    "        \"\"\"\n",
    "        self.alpha = args.alpha\n",
    "        self.beta = args.beta\n",
    "        self.gamma = args.gamma\n",
    "        self.m = args.m\n",
    "\n",
    "    def forward(self, data, update=True):\n",
    "        \"\"\"\n",
    "        Get the different relevant outputs for Intro VAE training\n",
    "        update=True to allow updating, update=False to keep networs constant\n",
    "        return x_re (reconstructed) and x_p (sampled)\n",
    "        \"\"\"\n",
    "        # 1. Send data to device\n",
    "        x = data[\"img\"].to(self.device)\n",
    "\n",
    "        # 2. Go trough the networks\n",
    "        # Reset Gradients\n",
    "        self.optimizerEnc.zero_grad()\n",
    "        self.optimizerDec.zero_grad()\n",
    "\n",
    "        # Encode\n",
    "        z_mu, z_log_sig2 = self.encoder(x)\n",
    "        # Apply reparametrisation and obtain z_enc\n",
    "        z_enc = self.reparametrisation(z_mu, z_log_sig2)\n",
    "        # Decode to reconstruct x\n",
    "        x_re = self.decoder(z_enc)\n",
    "        # Encode again to obtain z_re, while stopping gradient of x_re\n",
    "        z_re_mu, z_re_log_sig2 = self.encoder(x_re.detach())\n",
    "\n",
    "        # Take random z-vector\n",
    "        z_p = torch.randn_like(z_enc, device=self.device)\n",
    "        # Reconstruct random vector\n",
    "        x_p = self.decoder(z_p)\n",
    "        # Encode again to obtain z_pp, while stopping gradient of x_p\n",
    "        z_pp_mu, z_pp_log_sig2 = self.encoder(x_p.detach())\n",
    "\n",
    "        # 3. Determine the losses\n",
    "\n",
    "        # Autoencoder loss -> AE\n",
    "        l_rec = self.beta * self.ae_loss(x_re, x)\n",
    "\n",
    "        # Regression loss -> VAE\n",
    "        l_kl_z = self.gamma * self.kl_loss(z_mu, z_log_sig2)\n",
    "\n",
    "        # Adversarial Part: define regressions\n",
    "        l_kl_z_re = self.kl_loss(z_re_mu, z_re_log_sig2)\n",
    "        l_kl_z_pp = self.kl_loss(z_pp_mu, z_pp_log_sig2)\n",
    "\n",
    "        # Adversarial part for Encoder -> GAN\n",
    "        l_adv_enc = self.alpha * 0.5 * \\\n",
    "            (torch.clamp(self.m - l_kl_z_re, min=0) +\n",
    "             torch.clamp(self.m - l_kl_z_pp, min=0))\n",
    "\n",
    "        # Set loss of Enc\n",
    "        L_enc = l_rec + l_kl_z + l_adv_enc\n",
    "\n",
    "        # Update if necessary\n",
    "        if update:\n",
    "            # 4. Update Encoder\n",
    "            # ---------------------\n",
    "            # Backpropagate Enc loss while saving the losses\n",
    "            L_enc.backward(retain_graph=True)\n",
    "            # Update Enc\n",
    "            self.optimizerEnc.step()\n",
    "\n",
    "        # Encode again to obtain z_re, without stopping gradient of x_re\n",
    "        z_re_mu, z_re_log_sig2 = self.encoder(x_re)\n",
    "        # Encode again to obtain z_pp, without stopping gradient of x_p\n",
    "        z_pp_mu, z_pp_log_sig2 = self.encoder(x_p)\n",
    "\n",
    "        # recalculate losses\n",
    "        l_kl_z_re = self.kl_loss(z_re_mu, z_re_log_sig2)\n",
    "        l_kl_z_pp = self.kl_loss(z_pp_mu, z_pp_log_sig2)\n",
    "\n",
    "        # Adversarial part for Decoder -> GAN\n",
    "        l_adv_dec = self.alpha * 0.5 * (l_kl_z_re + l_kl_z_pp)\n",
    "\n",
    "        # Set loss of Dec\n",
    "        L_dec = 0\n",
    "        L_dec += l_adv_dec  # L_ae exists from backprop of previous branch already\n",
    "\n",
    "        # Update if necessary\n",
    "        if update:\n",
    "            # 5. Update Decoder\n",
    "            # ---------------------\n",
    "            L_dec.backward()\n",
    "            # Update Dec\n",
    "            self.optimizerDec.step()\n",
    "            # Return the Output\n",
    "            return x_re\n",
    "\n",
    "        else:\n",
    "            # Track the current losses\n",
    "            L_dec += l_rec + l_kl_z  # Add to watch true loss\n",
    "\n",
    "            # setup dictionary for Tracking\n",
    "            tr_data = {}\n",
    "            tr_data[\"l_rec\"] = l_rec.item()\n",
    "            tr_data[\"l_kl_zec\"] = l_kl_z.item()\n",
    "            tr_data[\"l_adv_enc\"] = l_adv_enc.item()\n",
    "            tr_data[\"l_adv_dec\"] = l_adv_dec.item()\n",
    "            tr_data[\"L_enc\"] = L_enc.item()\n",
    "            tr_data[\"L_dec\"] = L_dec.item()\n",
    "\n",
    "            # Return output and tracking data\n",
    "            return x_re, tr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from deeptool.train_loop import test_one_batch\n",
    "from deeptool.parameters import get_all_args, compat_args\n",
    "args = get_all_args()\n",
    "args.pic_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 dim test\n",
    "args.model_type = \"introvae\"\n",
    "args.dim = 3\n",
    "args = compat_args(args)\n",
    "test_one_batch(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 dim test\n",
    "args.dim = 2\n",
    "args = compat_args(args)\n",
    "test_one_batch(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dataloader.ipynb.\n",
      "Converted 01_architecture.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_parameters.ipynb.\n",
      "Converted 04_train_loop.ipynb.\n",
      "Converted 10_diagnosis.ipynb.\n",
      "Converted 20_dcgan.ipynb.\n",
      "Converted 21_introvae.ipynb.\n",
      "Converted 22_vqvae.ipynb.\n",
      "Converted 23_rnn_vae.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "82fdadc0-b84a-48d1-9b8e-d8a208951284"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
