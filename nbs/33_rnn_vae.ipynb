{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model.rnnvae\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from deeptool.architecture import Encoder, Decoder, DownUpConv\n",
    "from deeptool.abs_model import AbsModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN VAE\n",
    "\n",
    "> Structure for an Approach maintained a pseudo space realtion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/rnn_vae_arch.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 16, 256, 256])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load some test dataset to confirm architecture:\n",
    "from deeptool.parameters import get_all_args\n",
    "from deeptool.dataloader import load_test_batch\n",
    "\n",
    "args = get_all_args()\n",
    "args.model_type = \"rnnvae\"\n",
    "args.batch_size = 1\n",
    "args.track = False\n",
    "batch = load_test_batch(args)\n",
    "batch[\"img\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def mod_batch_2d(batch):\n",
    "    \"\"\"\n",
    "    transform the batch to be compatible with the network\n",
    "    \"\"\"\n",
    "    return batch\n",
    "\n",
    "\n",
    "def mod_batch_3d(batch, key=\"img\"):\n",
    "    \"\"\"\n",
    "    transform the batch to be compatible with the network by permuting\n",
    "    \"\"\"\n",
    "    if len(batch[key].shape) > 4:\n",
    "        batch[key] = batch[key][0, :, :, :, :]\n",
    "        batch[key] = batch[key].permute(1, 0, 2, 3)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 256, 256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchmod = mod_batch_3d(batch)\n",
    "batchmod[\"img\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    \"\"\"\n",
    "    Transition Network with Recurrence / 1D Convolutions / Identity Function\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(Transition, self).__init__()\n",
    "        self.define_switches(args)\n",
    "        self.n_z = args.n_z\n",
    "\n",
    "    def define_switches(self, args):\n",
    "        \"\"\"subfunc of init to define switches\"\"\"\n",
    "        # in = Identity mapping\n",
    "        ident = nn.Sequential()\n",
    "\n",
    "        # rnn = Recurrence\n",
    "        rnn = nn.Sequential(nn.GRU(args.n_z, args.n_z, 1),)\n",
    "\n",
    "        # cnn = 1d Convolution\n",
    "        cnn = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                args.n_z, args.n_z, kernel_size=3, dilation=1, padding=1, stride=1\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # switcher for the cnn part\n",
    "        switcher_part = {\n",
    "            \"ident\": ident,\n",
    "            \"rnn\": rnn,\n",
    "            \"cnn\": cnn,\n",
    "        }\n",
    "\n",
    "        # switcher for the functionality\n",
    "        switcher_func = {\n",
    "            \"ident\": self.forward_ident,\n",
    "            \"rnn\": self.forward_rnn,\n",
    "            \"cnn\": self.forward_cnn,\n",
    "        }\n",
    "\n",
    "        self.main_part = switcher_part.get(\n",
    "            args.rnn_transition, lambda: \"Invalid Transition Type\"\n",
    "        )\n",
    "        self.forward = switcher_func.get(\n",
    "            args.rnn_transition, lambda: \"Invalid Transition Type\"\n",
    "        )\n",
    "\n",
    "        print(\"Transition: \" + args.rnn_transition)\n",
    "\n",
    "    def forward_ident(self, x):\n",
    "        \"\"\"do not apply anything\"\"\"\n",
    "        return x\n",
    "\n",
    "    def forward_rnn(self, x):\n",
    "        \"\"\"\n",
    "        take the matrix of encoded input slices and apply the RNN part\n",
    "        \"\"\"\n",
    "        # reshape\n",
    "        x = x.reshape([1, -1, self.n_z])\n",
    "        # apply GRU layer\n",
    "        x, _ = self.main_part(x)\n",
    "        # reshape\n",
    "        x = x.reshape([-1, self.n_z])\n",
    "        # return result\n",
    "        return x\n",
    "\n",
    "    def forward_cnn(self, x):\n",
    "        \"\"\"apply cnn functionality\"\"\"\n",
    "        # reshape\n",
    "        x = x.reshape([1, self.n_z, -1])\n",
    "        # apply cnn layer\n",
    "        x = self.main_part(x)\n",
    "        # reshape\n",
    "        x = x.reshape([-1, self.n_z])\n",
    "        # return result\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from deeptool.train_loop import test_one_batch\n",
    "from deeptool.parameters import get_all_args, compat_args\n",
    "\n",
    "args = get_all_args()\n",
    "args.pic_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Simple Autoencoder with Recurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class RNNAE(AbsModel):\n",
    "    def __init__(self, device, args):\n",
    "        \"\"\"\n",
    "        The recurrent autoencoder for compressing 3d data.\n",
    "        It compresses in 2d while (hopefully) maintaining the spatial relation between layers\n",
    "        \"\"\"\n",
    "        super(RNNAE, self).__init__(args)\n",
    "        self.device = device\n",
    "\n",
    "        # 1. create the convolutional Encoder\n",
    "        self.true_dim = args.dim\n",
    "\n",
    "        args.dim = 2\n",
    "        \n",
    "        self.conv_part_enc = DownUpConv(\n",
    "            args,\n",
    "            pic_size=args.pic_size,\n",
    "            n_fea_in=len(args.perspectives),\n",
    "            n_fea_next=args.n_fea_up,\n",
    "            depth=1,\n",
    "        ).to(self.device)\n",
    "\n",
    "        # save important features\n",
    "        max_fea, min_size = self.conv_part_enc.max_fea, self.conv_part_enc.min_size\n",
    "        self.n_z, self.max_fea, self.min_size = args.n_z, max_fea, min_size\n",
    "\n",
    "        self.view_arr = [-1, max_fea * min_size ** 2]  # as flat vector\n",
    "        self.view_conv = [-1, max_fea, min_size, min_size]  # as conv block\n",
    "        self.view_track = [1, len(args.perspectives), -1, args.pic_size, args.pic_size]\n",
    "\n",
    "        # 2. Apply FC- Encoder Part\n",
    "        self.fc_part_enc = nn.Sequential(\n",
    "            nn.Linear(max_fea * min_size * min_size, max_fea * min_size),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(max_fea * min_size, max_fea),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(max_fea, args.n_z),\n",
    "        ).to(self.device)\n",
    "\n",
    "        # The Transition Part\n",
    "        self.transition = Transition(args).to(self.device)\n",
    "\n",
    "        # 4. Apply FC-Decoder Part\n",
    "        self.fc_part_dec = nn.Sequential(\n",
    "            nn.Linear(args.n_z, max_fea),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(max_fea, max_fea * min_size),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(max_fea * min_size, max_fea * min_size * min_size),\n",
    "        ).to(self.device)\n",
    "\n",
    "        # 5. create the convolutional Decoder\n",
    "        self.conv_part_dec = DownUpConv(\n",
    "            args,\n",
    "            pic_size=args.pic_size,\n",
    "            n_fea_in=len(args.perspectives),\n",
    "            n_fea_next=args.n_fea_down,\n",
    "            depth=1,\n",
    "            move=\"up\",\n",
    "        ).to(self.device)\n",
    "\n",
    "        # the standard loss\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "        # the optimizer\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=args.lr)\n",
    "\n",
    "        # reset the dimension\n",
    "        args.dim = self.true_dim\n",
    "        self.mod_batch = mod_batch_3d if args.dim == 3 else mod_batch_2d\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.conv_part_enc(x)\n",
    "        x = x.reshape(self.view_arr)\n",
    "        x = self.fc_part_enc(x)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x):\n",
    "        # apply transition\n",
    "        x = self.transition(x)\n",
    "        # decode\n",
    "        x = self.fc_part_dec(x)\n",
    "        x = x.reshape(self.view_conv)\n",
    "        x = self.conv_part_dec(x)\n",
    "        return x\n",
    "\n",
    "    def ae_forward(self, img):\n",
    "        # encode:\n",
    "        x = self.encode(img)\n",
    "        # decode\n",
    "        x = self.decode(x)\n",
    "        # calc loss\n",
    "        loss = self.mse_loss(img, x)\n",
    "        return loss, x\n",
    "\n",
    "    def forward(self, batch, update=True):\n",
    "        \"\"\"\n",
    "        calculate the forward pass\n",
    "        \"\"\"\n",
    "        # prepare\n",
    "        batch = self.mod_batch(batch)\n",
    "        img = self.prep(batch).to(self.device)\n",
    "\n",
    "        # autoencoder\n",
    "        loss, x = self.ae_forward(img)\n",
    "\n",
    "        if update:\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            return x\n",
    "\n",
    "        else:\n",
    "            tr_data = {}\n",
    "            tr_data[\"loss\"] = loss.item()\n",
    "\n",
    "        return x, tr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = nn.Sequential()\n",
    "a = 5\n",
    "trans(a) == a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition: cnn\n",
      "torch.Size([34, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transition(\n",
       "  (main_part): Sequential(\n",
       "    (0): Conv1d(100, 100, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.rnn_transition = \"cnn\"\n",
    "x = torch.randn(100, 34)\n",
    "tran = Transition(args)\n",
    "print(tran(x).shape)\n",
    "tran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-Type: rnnvae\n",
      "ae\n",
      "Transition: cnn\n"
     ]
    }
   ],
   "source": [
    "# 3 dim test\n",
    "args.model_type = \"rnnvae\"\n",
    "args.dataset_type = \"MRNet\"\n",
    "args.rnn_type = \"ae\"\n",
    "args.dim = 3\n",
    "args = compat_args(args)\n",
    "test_one_batch(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Variational Autoencoder in RNN Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class RNNVAE(RNNAE):\n",
    "    \"\"\"\n",
    "    inherit from RNN_AE and add the variational part\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device, args):\n",
    "        super(RNNVAE, self).__init__(device, args)\n",
    "        # 2. rewrite FC- Encoder Part\n",
    "        max_fea, min_size = self.max_fea, self.min_size\n",
    "        self.fc_part_enc = nn.Sequential(\n",
    "            nn.Linear(max_fea * min_size * min_size, max_fea * min_size),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(max_fea * min_size, max_fea),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(max_fea, 2 * args.n_z),\n",
    "            nn.Sigmoid(),\n",
    "        ).to(self.device)\n",
    "        # get the kl facor\n",
    "        self.gamma = args.gamma\n",
    "\n",
    "        # reset the optimizer\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=args.lr)\n",
    "\n",
    "    def vae_sampling(self, x):\n",
    "        mu, log_sig2 = x.chunk(2, dim=1)\n",
    "        # get random matrix\n",
    "        eps = torch.rand_like(mu, device=self.device)\n",
    "        # sample together\n",
    "        z = mu + torch.exp(torch.mul(0.5, log_sig2)) * eps\n",
    "        return z, mu, log_sig2\n",
    "\n",
    "    def kl_loss(self, mu, log_sig2):\n",
    "        return -0.5 * torch.sum(1 - torch.pow(mu, 2) - torch.exp(log_sig2) + log_sig2)\n",
    "\n",
    "    def forward(self, batch, update=True):\n",
    "        # prepare\n",
    "        batch = self.mod_batch(batch)\n",
    "        img = self.prep(batch).to(self.device)\n",
    "        # encode\n",
    "        x = self.encode(img)\n",
    "        # apply the vae sampling\n",
    "        x, mu, log_sig2 = self.vae_sampling(x)\n",
    "        # decode\n",
    "        x = self.decode(x)\n",
    "\n",
    "        # get loss\n",
    "        ae_loss = self.mse_loss(img, x)\n",
    "        vae_loss = self.kl_loss(mu, log_sig2)\n",
    "        loss = ae_loss + self.gamma * vae_loss\n",
    "\n",
    "        if update:\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            return x\n",
    "\n",
    "        else:\n",
    "            tr_data = {}\n",
    "            tr_data[\"loss\"] = loss.item()\n",
    "            tr_data[\"ae_loss\"] = ae_loss.item()\n",
    "            tr_data[\"vae_loss\"] = vae_loss.item()\n",
    "\n",
    "        return x, tr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-Type: rnnvae\n",
      "vae\n",
      "Transition: cnn\n"
     ]
    }
   ],
   "source": [
    "# 3 dim test\n",
    "args.model_type = \"rnnvae\"\n",
    "args.rnn_type = \"vae\"\n",
    "args.dim = 3\n",
    "args = compat_args(args)\n",
    "test_one_batch(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Intro-VAE with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class RNNINTROVAE(RNNVAE):\n",
    "    \"\"\"\n",
    "    inherit from RNN_VAE and add the GAN part\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device, args):\n",
    "        super(RNNINTROVAE, self).__init__(device, args)\n",
    "        # add extra parameters\n",
    "        self.alpha = args.alpha\n",
    "        self.beta = args.beta\n",
    "        self.gamma = args.gamma\n",
    "        self.m = args.m\n",
    "        self.n_pretrain = args.n_pretrain\n",
    "\n",
    "        # reset the optimizer\n",
    "        self.optimizer = None\n",
    "\n",
    "        enc_params = (\n",
    "            list(self.conv_part_enc.parameters())\n",
    "            + list(self.fc_part_enc.parameters())\n",
    "            + list(self.transition.parameters())\n",
    "        )\n",
    "        self.optimizerEnc = optim.Adam(enc_params, lr=args.lr)\n",
    "\n",
    "        dec_params = (\n",
    "            list(self.conv_part_dec.parameters())\n",
    "            + list(self.fc_part_dec.parameters())\n",
    "            + list(self.transition.parameters())\n",
    "        )\n",
    "        self.optimizerDec = optim.Adam(dec_params, lr=args.lr)\n",
    "    \n",
    "    def forward(self, batch, update=True):\n",
    "        \"\"\"\n",
    "        Get the different relevant outputs for Intro VAE training\n",
    "        update=True to allow updating, update=False to keep networs constant\n",
    "        return x_re (reconstructed)\n",
    "        \"\"\"\n",
    "        batch = self.mod_batch(batch)\n",
    "        x = self.prep(batch).to(self.device)\n",
    "        \n",
    "        #=========== Update E ================\n",
    "        self.optimizerEnc.zero_grad()\n",
    "        \n",
    "        # real\n",
    "        z = self.encode(x)\n",
    "        z, z_mu, z_log_sig2 = self.vae_sampling(z)\n",
    "        x_re = self.decode(z)\n",
    "        \n",
    "        # fake\n",
    "        noise = torch.randn_like(z, device=self.device)\n",
    "        fake = self.decode(noise)\n",
    "        \n",
    "        # encode again\n",
    "        z_re = self.encode(x_re.detach())\n",
    "        _, z_mu_re, z_log_sig2_re = self.vae_sampling(z_re)\n",
    "        \n",
    "        z_fake = self.encode(fake.detach())\n",
    "        _, z_mu_fake, z_log_sig2_fake = self.vae_sampling(z_fake)\n",
    "        \n",
    "        # get losses\n",
    "        loss_rec = self.mse_loss(x, x_re)\n",
    "        loss_e_real_kl = self.kl_loss(z_mu, z_log_sig2)\n",
    "        loss_e_rec_kl = self.kl_loss(z_mu_re, z_log_sig2_re)\n",
    "        loss_e_fake_kl = self.kl_loss(z_mu_fake, z_log_sig2_fake)\n",
    "        \n",
    "        # combine losses\n",
    "        loss_margin_e = loss_e_real_kl + (F.relu(self.m - loss_e_rec_kl) + F.relu(self.m - loss_e_fake_kl)) * self.alpha\n",
    "        loss_e = loss_rec * self.beta + loss_margin_e * self.gamma\n",
    "        \n",
    "        if update:\n",
    "            loss_e.backward()\n",
    "            self.optimizerEnc.step()\n",
    "        \n",
    "        #========= Update G ================== \n",
    "        self.optimizerDec.zero_grad()\n",
    "        \n",
    "        # real\n",
    "        z = self.encode(x)\n",
    "        z, z_mu, z_log_sig2 = self.vae_sampling(z)\n",
    "        x_re = self.decode(z)\n",
    "        \n",
    "        # fake\n",
    "        noise = torch.randn_like(z, device=self.device)\n",
    "        fake = self.decode(noise)\n",
    "        \n",
    "        # encode again\n",
    "        z_re = self.encode(x_re)\n",
    "        _, z_mu_re, z_log_sig2_re = self.vae_sampling(z_re)\n",
    "        \n",
    "        z_fake = self.encode(fake)\n",
    "        _, z_mu_fake, z_log_sig2_fake = self.vae_sampling(z_fake)\n",
    "        \n",
    "        # get losses\n",
    "        loss_rec = self.mse_loss(x, x_re)\n",
    "        loss_g_real_kl = self.kl_loss(z_mu, z_log_sig2)\n",
    "        loss_g_rec_kl = self.kl_loss(z_mu_re, z_log_sig2_re)\n",
    "        loss_g_fake_kl = self.kl_loss(z_mu_fake, z_log_sig2_fake)\n",
    "        \n",
    "        # combine losses\n",
    "        loss_margin_g = loss_g_real_kl * (loss_g_rec_kl + loss_g_fake_kl) * self.alpha\n",
    "        loss_g = loss_rec * self.beta + loss_margin_g * self.gamma\n",
    "        \n",
    "        if update:\n",
    "            loss_g.backward()\n",
    "            self.optimizerDec.step()\n",
    "        \n",
    "        else:\n",
    "            # setup dictionary for Tracking\n",
    "            tr_data = {}\n",
    "            tr_data[\"loss_rec\"] = loss_rec.item()\n",
    "            tr_data[\"loss_e_real_kl\"] = loss_e_real_kl.item()\n",
    "            tr_data[\"loss_margin_e\"] = loss_margin_e.item()\n",
    "            tr_data[\"loss_margin_g\"] = loss_margin_g.item()\n",
    "            tr_data[\"loss_e\"] = loss_e.item()\n",
    "            tr_data[\"loss_g\"] = loss_g.item()\n",
    "\n",
    "            # Return output and tracking data\n",
    "            return x_re, tr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-Type: rnnvae\n",
      "introvae\n",
      "Transition: cnn\n"
     ]
    }
   ],
   "source": [
    "# 3 dim test\n",
    "args.model_type = \"rnnvae\"\n",
    "args.rnn_type = \"introvae\"\n",
    "args.dim = 3\n",
    "args = compat_args(args)\n",
    "test_one_batch(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture:\n",
    "<img src=\"img/arch_biggan.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "### Loss:\n",
    "<img src=\"img/biggan.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "\n",
    "(by: https://arxiv.org/pdf/1907.02544.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class RNNBIGAN(RNNVAE):\n",
    "    \"\"\"\n",
    "    apply the Bidirectional-GAN part, inherit from the normal autoencoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device, args):\n",
    "        \"\"\"\n",
    "        init the networks and the discriminator\n",
    "        \"\"\"\n",
    "        # init the vae architecture\n",
    "        super(RNNBIGAN, self).__init__(device, args)\n",
    "        # we ned a dicriminator!\n",
    "        # switch to 2 dim for the init:\n",
    "        # -----------\n",
    "        args.dim = 2\n",
    "        self.conv_part_dis = DownUpConv(\n",
    "            args,\n",
    "            pic_size=args.pic_size,\n",
    "            n_fea_in=len(args.perspectives),\n",
    "            n_fea_next=args.n_fea_up,\n",
    "            depth=1,\n",
    "        ).to(self.device)\n",
    "        args.dim = 3\n",
    "        # -----------\n",
    "\n",
    "        # take saved params\n",
    "        max_fea, min_size, n_z = self.max_fea, self.min_size, args.n_z\n",
    "\n",
    "        # add the fc part(s)\n",
    "        self.fc_part_dis_x = nn.Sequential(\n",
    "            # layer 1\n",
    "            nn.Linear(max_fea * min_size * min_size, max_fea * min_size),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # layer 2\n",
    "            nn.Linear(max_fea * min_size, max_fea),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # layer 3\n",
    "            nn.Linear(max_fea, max_fea),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # layer 4\n",
    "            nn.Linear(max_fea, 1),\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.fc_part_dis_z = nn.Sequential(\n",
    "            # layer 1\n",
    "            nn.Linear(n_z, max_fea),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # layer 2\n",
    "            nn.Linear(max_fea, max_fea),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # layer 3\n",
    "            nn.Linear(max_fea, 1),\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.fc_part_dis_xz = nn.Sequential(\n",
    "            # layer 1\n",
    "            nn.Linear(n_z + max_fea * min_size * min_size, max_fea * min_size),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # layer 2\n",
    "            nn.Linear(max_fea * min_size, max_fea),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # layer 3\n",
    "            nn.Linear(max_fea, max_fea),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # layer 4\n",
    "            nn.Linear(max_fea, 1),\n",
    "        ).to(self.device)\n",
    "\n",
    "        # reset the optimizer\n",
    "        self.optimizer = None\n",
    "\n",
    "        enc_params = list(self.conv_part_enc.parameters()) + list(\n",
    "            self.fc_part_enc.parameters()\n",
    "        )\n",
    "        self.optimizerEnc = optim.Adam(enc_params, lr=args.lr)\n",
    "\n",
    "        dec_params = (\n",
    "            list(self.conv_part_dec.parameters())\n",
    "            + list(self.fc_part_dec.parameters())\n",
    "            + list(self.transition.parameters())\n",
    "        )\n",
    "        self.optimizerDec = optim.Adam(dec_params, lr=args.lr)\n",
    "\n",
    "        dis_params = (\n",
    "            list(self.conv_part_dis.parameters())\n",
    "            + list(self.fc_part_dis_x.parameters())\n",
    "            + list(self.fc_part_dis_z.parameters())\n",
    "            + list(self.fc_part_dis_xz.parameters())\n",
    "        )\n",
    "        self.optimizerDis = optim.Adam(dis_params, lr=args.lr)\n",
    "\n",
    "        # parameters\n",
    "        self.lam = args.lam\n",
    "        self.bi_ae_scale = args.bi_ae_scale\n",
    "\n",
    "    def encode_non_d(self, x):\n",
    "        \"\"\"non-deterministic encoding from the paper\"\"\"\n",
    "        x = self.encode(x)\n",
    "        # get mu and sigma\n",
    "        mu, sig_hat = x.chunk(2, dim=1)\n",
    "        sig = torch.log(1 + torch.exp(sig_hat))\n",
    "        # get random matrix\n",
    "        eps = torch.rand_like(mu, device=self.device)\n",
    "        # sample together\n",
    "        z = mu + sig * eps\n",
    "        return z\n",
    "\n",
    "    def get_s(self, x, z):\n",
    "        \"\"\"apply discriminator and output sx, sz and sxz\"\"\"\n",
    "        # shape inputs\n",
    "        x = self.conv_part_dis(x)\n",
    "        x = x.reshape(self.view_arr)\n",
    "        xz = torch.cat([x, z], dim=1)\n",
    "\n",
    "        # apply fc decisions to generate out-dis\n",
    "        s_x = self.fc_part_dis_x(x).view(-1)\n",
    "        s_z = self.fc_part_dis_z(z).view(-1)\n",
    "        s_xz = self.fc_part_dis_xz(xz).view(-1)\n",
    "\n",
    "        return s_x, s_z, s_xz\n",
    "\n",
    "    def hinge(self, x):\n",
    "        \"\"\"the hinge loss: max(0, 1-x)\"\"\"\n",
    "        return F.relu(1 - x)\n",
    "\n",
    "    def decide(self, x, z, y, ed=False):\n",
    "        \"\"\"\n",
    "        generate dis-loss\n",
    "        ed -> ENCODE-DECODE Learning\n",
    "        \"\"\"\n",
    "        # get decisions from Discriminator\n",
    "        s_x, s_z, s_xz = self.get_s(x, z)\n",
    "\n",
    "        # apply y for encoder-decoder\n",
    "        if ed:\n",
    "            return y * (s_x + s_z + s_xz)\n",
    "\n",
    "        # apply hinge losses for discriminator\n",
    "        hs_x = self.hinge(y * s_x)\n",
    "        hs_z = self.hinge(y * s_z)\n",
    "        hs_xz = self.hinge(y * s_xz)\n",
    "\n",
    "        return hs_x + hs_z + hs_xz\n",
    "\n",
    "    def ae_part(self, x, update):\n",
    "        \"\"\"simple forward pass of autoencoder\"\"\"\n",
    "        ae_loss, _ = self.ae_forward(x)\n",
    "        ae_loss *= self.bi_ae_scale\n",
    "\n",
    "        if update:\n",
    "            ae_loss.backward()\n",
    "        return ae_loss.mean().item()\n",
    "\n",
    "    def forward(self, batch, update=True):\n",
    "        \"\"\"main function\"\"\"\n",
    "        # zero all gradients\n",
    "        self.optimizerEnc.zero_grad()\n",
    "        self.optimizerDec.zero_grad()\n",
    "        self.optimizerDis.zero_grad()\n",
    "\n",
    "        # (0) Train Autoencoder\n",
    "        # -------------------------------\n",
    "        ae_loss = 0\n",
    "        # ae_loss = self.ae_part(x, update)\n",
    "\n",
    "        # (1) Train Discriminator\n",
    "        # -------------------------------\n",
    "        # load batch\n",
    "        batch = self.mod_batch(batch)\n",
    "        x = self.prep(batch).to(self.device)\n",
    "        # generate original z\n",
    "        z = self.encode_non_d(x)\n",
    "\n",
    "        # fake\n",
    "        z_p = torch.randn_like(z, device=self.device)\n",
    "        # decode\n",
    "        x_p = self.decode(z_p)\n",
    "\n",
    "        # real\n",
    "        errd_real = self.decide(x.detach(), z.detach(), +1).mean()\n",
    "        if update:\n",
    "            errd_real.backward()\n",
    "\n",
    "        # fake\n",
    "        errd_fake = self.decide(x_p.detach(), z_p.detach(), -1).mean()\n",
    "\n",
    "        if update:\n",
    "            errd_fake.backward()\n",
    "            self.optimizerDis.step()\n",
    "\n",
    "        errd = (errd_real + errd_fake).mean().item()\n",
    "\n",
    "        # (2) Train Encoder / Decoder\n",
    "        # -------------------------------\n",
    "        # encode\n",
    "        z = self.encode_non_d(x)\n",
    "\n",
    "        # decode\n",
    "        x_p = self.decode(z_p)\n",
    "\n",
    "        # real\n",
    "        err_enc = self.decide(x, z, +1, ed=True).mean()\n",
    "\n",
    "        if update:\n",
    "            err_enc.backward()\n",
    "\n",
    "        # fake\n",
    "        err_dec = self.decide(x_p, z_p, -1, ed=True).mean()\n",
    "\n",
    "        err_enc_dec = (err_enc + err_dec).mean().item()\n",
    "\n",
    "        # Update Generator\n",
    "        if update:\n",
    "            err_dec.backward()\n",
    "            self.optimizerEnc.step()\n",
    "            self.optimizerDec.step()\n",
    "            return x_p\n",
    "\n",
    "        else:\n",
    "            # Track all relevant losses\n",
    "            tr_data = {}\n",
    "            tr_data[\"ae_loss\"] = ae_loss\n",
    "            tr_data[\"errDis\"] = errd\n",
    "            tr_data[\"errEncDec\"] = err_enc_dec\n",
    "\n",
    "            tr_data[\"errD_real\"] = errd_real.mean().item()\n",
    "            tr_data[\"errD_fake\"] = errd_fake.mean().item()\n",
    "\n",
    "            tr_data[\"errEnc\"] = err_enc.mean().item()\n",
    "            tr_data[\"errDec\"] = err_dec.mean().item()\n",
    "\n",
    "            # generate the autoencoder output:\n",
    "            x_r = self.decode(z)\n",
    "\n",
    "            # Return losses and reconstruction data\n",
    "            return x_r, tr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def creator_rnn_ae(device, args):\n",
    "    \"\"\"\n",
    "    return an instance of the class depending on the mode set in args\n",
    "    \"\"\"\n",
    "    switcher = {\n",
    "        \"ae\": RNNAE,\n",
    "        \"vae\": RNNVAE,\n",
    "        \"introvae\": RNNINTROVAE,\n",
    "        \"bigan\": RNNBIGAN,\n",
    "    }\n",
    "    print(args.rnn_type)\n",
    "    # Get the model_creator\n",
    "    model_creator = switcher.get(args.rnn_type, lambda: \"Invalid Model Type\")\n",
    "    return model_creator(device, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition: cnn\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 32, 32])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    \"cuda:0\" if (torch.cuda.is_available() and args.n_gpu > 0) else \"cpu\"\n",
    ")\n",
    "rnn_bigan = RNNBIGAN(device, args)\n",
    "data = load_test_batch(args)\n",
    "x, tr = rnn_bigan(data, update=False)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dataloader.ipynb.\n",
      "Converted 01_architecture.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_parameters.ipynb.\n",
      "Converted 04_train_loop.ipynb.\n",
      "Converted 05_abstract_model.ipynb.\n",
      "Converted 10_diagnosis.ipynb.\n",
      "Converted 20_dcgan.ipynb.\n",
      "Converted 21_introvae.ipynb.\n",
      "Converted 22_vqvae.ipynb.\n",
      "Converted 23_bigan.ipynb.\n",
      "Converted 24_mocoae.ipynb.\n",
      "Converted 33_rnn_vae.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
