{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model.rnnvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from deeptool.architecture import Encoder, Decoder, DownUpConv\n",
    "from deeptool.utils import Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN VAE\n",
    "\n",
    "> Structure for an Approach maintained a pseudo space realtion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/rnn_vae_arch.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 16, 256, 256])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load some test dataset to confirm architecture:\n",
    "from deeptool.parameters import get_all_args\n",
    "from deeptool.dataloader import load_test_batch\n",
    "args = get_all_args()\n",
    "args.model_type = \"rnnvae\"\n",
    "args.batch_size = 1\n",
    "args.track = False\n",
    "batch = load_test_batch(args)\n",
    "batch[\"img\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def mod_batch(batch, key=\"img\"):\n",
    "    \"\"\"\n",
    "    transform the batch to be compatible with the network by permuting\n",
    "    \"\"\"\n",
    "    if len(batch[key].shape) > 4:\n",
    "        batch[key] = batch[key][0, :, :, :, :]\n",
    "        batch[key] = batch[key].permute(1, 0, 2, 3)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 256, 256])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchmod = mod_batch(batch)\n",
    "batchmod[\"img\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Simple Autoencoder with Recurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class RNN_AE(nn.Module):\n",
    "\n",
    "    def __init__(self, device, args):\n",
    "        \"\"\"\n",
    "        The recurrent autoencoder for compressing 3d data.\n",
    "        It compresses in 2d while (hopefully) maintaining the spatial relation between layers\n",
    "        \"\"\"\n",
    "        super(RNN_AE, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "        # 1. create the convolutional Encoder\n",
    "        args.dim = 2\n",
    "        self.conv_part_enc = DownUpConv(args, pic_size=args.pic_size, n_fea_in=len(\n",
    "            args.perspectives), n_fea_next=args.n_fea_up, depth=1).to(self.device)\n",
    "\n",
    "        # save important features\n",
    "        max_fea, min_size = self.conv_part_enc.max_fea, self.conv_part_enc.min_size\n",
    "        self.n_z, self.max_fea, self.min_size = args.n_z, max_fea, min_size\n",
    "\n",
    "        self.view_arr = [-1, max_fea * min_size**2]  # as flat vector\n",
    "        self.view_conv = [-1, max_fea, min_size, min_size]  # as conv block\n",
    "        self.view_track = [1, len(args.perspectives), -1,\n",
    "                           args.pic_size, args.pic_size]\n",
    "\n",
    "        # 2. Apply FC- Encoder Part\n",
    "        self.fc_part_enc = nn.Sequential(\n",
    "            nn.Linear(max_fea*min_size*min_size, max_fea*min_size),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(max_fea*min_size, max_fea),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(max_fea, args.n_z),\n",
    "        ).to(self.device)\n",
    "\n",
    "        # 3. Transition Layer: \n",
    "        if args.rnn_active:\n",
    "            # Apply a RECURRENCE\n",
    "            self.transition = nn.GRU(args.n_z, args.n_z, 1).to(self.device)\n",
    "        else:\n",
    "            # simple Identity\n",
    "            self.transition = nn.Sequential()\n",
    "        \n",
    "        # 4. Apply FC-Decoder Part\n",
    "        self.fc_part_dec = nn.Sequential(\n",
    "            nn.Linear(args.n_z, max_fea),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(max_fea, max_fea*min_size),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(max_fea*min_size, max_fea*min_size*min_size),\n",
    "        ).to(self.device)\n",
    "\n",
    "        # 5. create the convolutional Decoder\n",
    "        self.conv_part_dec = DownUpConv(\n",
    "            args, pic_size=args.pic_size, n_fea_in=len(\n",
    "                args.perspectives), n_fea_next=args.n_fea_down, depth=1, move='up').to(self.device)\n",
    "\n",
    "        # the standard loss\n",
    "        self.mse_loss = nn.MSELoss(reduction='sum')\n",
    "\n",
    "        # the optimizer\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=args.lr)\n",
    "\n",
    "        # reset the dimension\n",
    "        args.dim = 3\n",
    "\n",
    "        # Setup the tracker to visualize the progress\n",
    "        if args.track:\n",
    "            self.tracker = Tracker(args)\n",
    "\n",
    "    def watch_progress(self, test_data, iteration):\n",
    "        \"\"\"Outsourced to Tracker\"\"\"\n",
    "        self.tracker.track_progress(self, test_data, iteration)\n",
    "\n",
    "    def rnn_transition(self, x):\n",
    "        \"\"\"\n",
    "        take the matrix of encoded input slices and apply the RNN part\n",
    "        \"\"\"\n",
    "        # reshape\n",
    "        x = x.reshape([-1, 1, self.n_z])\n",
    "        # apply GRU layer\n",
    "        x, _ = self.transition(x)\n",
    "        # reshape\n",
    "        x = x.reshape([-1, self.n_z])\n",
    "        return x\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.conv_part_enc(x)\n",
    "        x = x.reshape(self.view_arr)\n",
    "        x = self.fc_part_enc(x)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x):\n",
    "        # apply transition\n",
    "        x = self.rnn_transition(x)\n",
    "        # decode\n",
    "        x = self.fc_part_dec(x)\n",
    "        x = x.reshape(self.view_conv)\n",
    "        x = self.conv_part_dec(x)\n",
    "        return x\n",
    "\n",
    "    def prep_input(self, batch):\n",
    "        self.zero_grad()\n",
    "        batch = mod_batch(batch)\n",
    "        img = batch['img'].to(self.device)\n",
    "        return img\n",
    "    \n",
    "    def ae_forward(self, img):\n",
    "        # encode:\n",
    "        x = self.encode(img)\n",
    "        # decode\n",
    "        x = self.decode(x)\n",
    "        # calc loss\n",
    "        loss = self.mse_loss(img, x)\n",
    "        return loss, x\n",
    "\n",
    "    def forward(self, batch, update=True):\n",
    "        \"\"\"\n",
    "        calculate the forward pass\n",
    "        \"\"\"\n",
    "        # prepare\n",
    "        img = self.prep_input(batch)\n",
    "        # autoencoder\n",
    "        loss, x = self.ae_forward(img)\n",
    "\n",
    "        if update:\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            return x\n",
    "\n",
    "        else:\n",
    "            tr_data = {}\n",
    "            tr_data[\"loss\"] = loss.item()\n",
    "\n",
    "        return x, tr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = nn.Sequential()\n",
    "a = 5\n",
    "trans(a) == a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from deeptool.train_loop import test_one_batch\n",
    "from deeptool.parameters import get_all_args, compat_args\n",
    "args = get_all_args()\n",
    "args.pic_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnnvae\n"
     ]
    }
   ],
   "source": [
    "# 3 dim test\n",
    "args.model_type = \"rnnvae\"\n",
    "args.rnn_type = \"ae\"\n",
    "args.dim = 3\n",
    "args = compat_args(args)\n",
    "test_one_batch(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Variational Autoencoder in RNN Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class RNN_VAE(RNN_AE):\n",
    "    \"\"\"\n",
    "    inherit from RNN_AE and add the variational part\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device, args):\n",
    "        #super(RNN_AE, self).__init__(device, args)\n",
    "        RNN_AE.__init__(self, device, args)\n",
    "        # 2. rewrite FC- Encoder Part\n",
    "        max_fea, min_size = self.max_fea, self.min_size\n",
    "        self.fc_part_enc = nn.Sequential(\n",
    "            nn.Linear(max_fea*min_size*min_size, max_fea*min_size),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(max_fea*min_size, max_fea),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(max_fea, 2 * args.n_z),\n",
    "        ).to(self.device)\n",
    "        # get the kl facor\n",
    "        self.gamma = args.gamma\n",
    "\n",
    "    def vae_sampling(self, x):\n",
    "        mu, log_sig2 = x.chunk(2, dim=1)\n",
    "        # get random matrix\n",
    "        eps = torch.rand_like(\n",
    "            mu, device=self.device)\n",
    "        # sample together\n",
    "        z = mu + torch.exp(torch.mul(0.5, log_sig2)) * eps\n",
    "        return z, mu, log_sig2\n",
    "\n",
    "    def kl_loss(self, mu, log_sig2):\n",
    "        return -0.5 * torch.sum(1 - torch.pow(mu, 2) - torch.exp(log_sig2) + log_sig2)\n",
    "\n",
    "    def forward(self, batch, update=True):\n",
    "        # prepare\n",
    "        img = self.prep_input(batch)\n",
    "        # encode\n",
    "        x = self.encode(img)\n",
    "        # apply the vae sampling\n",
    "        x, mu, log_sig2 = self.vae_sampling(x)\n",
    "        # decode\n",
    "        x = self.decode(x)\n",
    "\n",
    "        # get loss\n",
    "        ae_loss = self.mse_loss(img, x)\n",
    "        vae_loss = self.kl_loss(mu, log_sig2)\n",
    "        loss = ae_loss + self.gamma * vae_loss\n",
    "\n",
    "        if update:\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            return x\n",
    "\n",
    "        else:\n",
    "            tr_data = {}\n",
    "            tr_data[\"loss\"] = loss.item()\n",
    "            tr_data[\"ae_loss\"] = ae_loss.item()\n",
    "            tr_data[\"vae_loss\"] = vae_loss.item()\n",
    "\n",
    "        return x, tr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnnvae\n"
     ]
    }
   ],
   "source": [
    "# 3 dim test\n",
    "args.model_type = \"rnnvae\"\n",
    "args.rnn_type= \"vae\"\n",
    "args.dim = 3\n",
    "args = compat_args(args)\n",
    "test_one_batch(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Intro-VAE with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class RNN_INTROVAE(RNN_VAE):\n",
    "    \"\"\"\n",
    "    inherit from RNN_VAE and add the GAN part\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device, args):\n",
    "        # super(RNN_AE, self).__init__(device, args)\n",
    "        RNN_VAE.__init__(self, device, args)\n",
    "        # add extra parameters\n",
    "        self.alpha = args.alpha\n",
    "        self.beta = args.beta\n",
    "        self.gamma = args.gamma\n",
    "        self.m = args.m\n",
    "        self.n_pretrain = args.n_pretrain\n",
    "\n",
    "        enc_params = list(self.conv_part_enc.parameters(\n",
    "        )) + list(self.fc_part_enc.parameters()) + list(self.transition.parameters())\n",
    "        self.optimizerEnc = optim.Adam(enc_params, lr=args.lr)\n",
    "\n",
    "        dec_params = list(self.conv_part_dec.parameters(\n",
    "        )) + list(self.fc_part_dec.parameters()) + list(self.transition.parameters())\n",
    "        self.optimizerDec = optim.Adam(dec_params, lr=args.lr)\n",
    "\n",
    "    def forward(self, batch, update=True):\n",
    "\n",
    "        # prepare\n",
    "        self.optimizer.zero_grad()\n",
    "        img = self.prep_input(batch)\n",
    "\n",
    "        # (1st) Pass Original\n",
    "        # --------------------------------------\n",
    "        # encode\n",
    "        z = self.encode(img)\n",
    "        z, mu, log_sig2 = self.vae_sampling(z)\n",
    "\n",
    "        # decode\n",
    "        x_re = self.decode(z)\n",
    "\n",
    "        # Losses\n",
    "        ae_loss = self.beta * self.mse_loss(img, x_re)\n",
    "        kl_loss = self. gamma * self.kl_loss(mu, log_sig2)\n",
    "\n",
    "        # (2nd) Pass Reconstruct Original (Enc)\n",
    "        # --------------------------------------\n",
    "        # encode\n",
    "        z_re_1 = self.encode(x_re.detach())\n",
    "        z_re_1, mu_re_1, log_sig2_re_1 = self.vae_sampling(z_re_1)\n",
    "\n",
    "        # Losses\n",
    "        kl_loss_re_e = self.kl_loss(mu_re_1, log_sig2_re_1)\n",
    "\n",
    "        # (3rd) Pass Generate Fake imgs (Enc)\n",
    "        # --------------------------------------\n",
    "        # generate fake samples\n",
    "        z_p = torch.randn_like(z, device=self.device)       \n",
    "\n",
    "        # decode\n",
    "        x_p = self.decode(z_p)\n",
    "\n",
    "        # encode (xp stopped!)\n",
    "        z_p_re_1 = self.encode(x_p.detach())\n",
    "        z_p_re_1, mu_p_re_1, log_sig2_re_1 = self.vae_sampling(z_p_re_1)\n",
    "\n",
    "        # Losses\n",
    "        kl_loss_p_e = self.kl_loss(mu_p_re_1, log_sig2_re_1)\n",
    "\n",
    "        # -------\n",
    "        l_adv_e = self.alpha * \\\n",
    "            0.5 * (torch.clamp(self.m - kl_loss_re_e, min=0) +\n",
    "                   torch.clamp(self.m - kl_loss_p_e, min=0))\n",
    "        L_e = ae_loss + kl_loss + l_adv_e\n",
    "\n",
    "        if update:\n",
    "            L_e.backward(retain_graph=True)\n",
    "            self.optimizerEnc.step()\n",
    "        # ------\n",
    "\n",
    "        # (4th) Pass Reconstruct Original (Dec)\n",
    "        # --------------------------------------\n",
    "        # encode (x_re free)\n",
    "        z_re_2 = self.encode(x_re)\n",
    "        z_re_2, mu_re_2, log_sig2_re_2 = self.vae_sampling(z_re_2)\n",
    "\n",
    "        # Losses\n",
    "        kl_loss_re_d = self.kl_loss(mu_re_2, log_sig2_re_2)\n",
    "\n",
    "        # (5th) Pass Generate Fake imgs (Dec)\n",
    "        # --------------------------------------\n",
    "        # encode (xp free)\n",
    "        z_p_re_2 = self.encode(x_p)\n",
    "        z_p_re_2, mu_p_re_2, log_sig2_re_2 = self.vae_sampling(z_p_re_2)\n",
    "\n",
    "        # Losses\n",
    "        kl_loss_p_d = self.kl_loss(mu_p_re_1, log_sig2_re_1)\n",
    "\n",
    "        L_d = self.alpha * 0.5 * (kl_loss_re_d + kl_loss_p_d)\n",
    "\n",
    "        # ------\n",
    "        if update:\n",
    "            L_d.backward()\n",
    "            self.optimizerDec.step()\n",
    "            return x_re\n",
    "        # ------\n",
    "\n",
    "        else:\n",
    "            tr_data = {}\n",
    "            tr_data[\"L_encoder\"] = L_e.item()\n",
    "            tr_data[\"L_decoder\"] = L_d.item() + ae_loss.item() + kl_loss.item()\n",
    "            tr_data[\"ae_loss\"] = ae_loss.item()\n",
    "            tr_data[\"vae_loss\"] = kl_loss.item()\n",
    "            tr_data[\"l_adv_e\"] = l_adv_e.item()\n",
    "            tr_data[\"l_adv_d\"] = L_d.item()\n",
    "\n",
    "        return x_re, tr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnnvae\n"
     ]
    }
   ],
   "source": [
    "# 3 dim test\n",
    "args.model_type = \"rnnvae\"\n",
    "args.rnn_type= \"introvae\"\n",
    "args.dim = 3\n",
    "args = compat_args(args)\n",
    "test_one_batch(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/bigan_rae_1.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "class RNN_BIGAN(RNN_AE):\n",
    "    \"\"\"\n",
    "    apply the Bidirectional-GAN part, inherit from the normal autoencoder\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, device, args):\n",
    "        \"\"\"\n",
    "        init the networks and the discriminator\n",
    "        \"\"\"\n",
    "        # init the vae architecture\n",
    "        RNN_AE.__init__(self, device, args)\n",
    "        # we ned a dicriminator!\n",
    "        # switch to 2 dim for the init:\n",
    "        # -----------\n",
    "        args.dim = 2\n",
    "        self.conv_part_dis = DownUpConv(args, pic_size=args.pic_size, n_fea_in=len(\n",
    "            args.perspectives), n_fea_next=args.n_fea_up, depth=1).to(self.device)\n",
    "        args.dim = 3\n",
    "        # -----------\n",
    "        \n",
    "        # take saved params\n",
    "        max_fea, min_size, n_z = self.max_fea, self.min_size, args.n_z\n",
    "        #add the fc part\n",
    "        self.fc_part_dis = nn.Sequential(\n",
    "            nn.Linear(n_z+max_fea*min_size*min_size, max_fea*min_size),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(max_fea*min_size, max_fea),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(max_fea, 1),\n",
    "            nn.Sigmoid(),\n",
    "        ).to(self.device)\n",
    "        \n",
    "        enc_params = list(self.conv_part_enc.parameters(\n",
    "        )) + list(self.fc_part_enc.parameters())\n",
    "        self.optimizerEnc = optim.Adam(enc_params, lr=args.lr)\n",
    "\n",
    "        dec_params = list(self.conv_part_dec.parameters(\n",
    "        )) + list(self.fc_part_dec.parameters()) + list(self.transition.parameters())\n",
    "        self.optimizerDec = optim.Adam(dec_params, lr=args.lr)\n",
    "        \n",
    "        dis_params = list(self.conv_part_dis.parameters(\n",
    "        )) + list(self.fc_part_dis.parameters())\n",
    "        self.optimizerDis = optim.Adam(dis_params, lr=args.lr)\n",
    "        \n",
    "        # labeling\n",
    "        self.real_label = 1\n",
    "        self.fake_label = 0\n",
    "        \n",
    "        # parameters\n",
    "        self.lam = args.lam\n",
    "        self.bi_ae_scale = args.bi_ae_scale\n",
    "        \n",
    "        # Loss to be optimized for dcgan\n",
    "        self.bi_loss = nn.BCELoss()\n",
    "    \n",
    "    def decide(self, x, z):\n",
    "        \"\"\"apply discriminator\"\"\"\n",
    "        x = self.conv_part_dis(x)\n",
    "        x = x.reshape(self.view_arr)\n",
    "        xz = torch.cat([x, z], dim=1)\n",
    "        xz = self.fc_part_dis(xz)\n",
    "        return xz.view(-1)\n",
    "    \n",
    "    def ae_part(self, x, update):\n",
    "        ae_loss, _ = self.ae_forward(x)\n",
    "        ae_loss *= self.bi_ae_scale\n",
    "        if update:\n",
    "            ae_loss.backward()\n",
    "        return ae_loss.mean().item()\n",
    "        \n",
    "    def forward(self, batch, update=True):\n",
    "        \"\"\"main function\"\"\"\n",
    "        # zero all gradients\n",
    "        self.optimizerEnc.zero_grad()\n",
    "        self.optimizerDec.zero_grad()\n",
    "        self.optimizerDis.zero_grad()\n",
    "        \n",
    "        # load batch\n",
    "        x = self.prep_input(batch)\n",
    "        \n",
    "        # (0) Train Autoencoder\n",
    "        #-------------------------------\n",
    "        ae_loss = 0\n",
    "        #ae_loss = self.ae_part(x, update)\n",
    "        \n",
    "        # (1) Train Discriminator\n",
    "        #-------------------------------\n",
    "        # load batch\n",
    "        x = self.prep_input(batch)\n",
    "        # generate original z\n",
    "        z = self.encode(x)\n",
    "        \n",
    "        # fake\n",
    "        z_p = torch.randn_like(z, device=self.device)\n",
    "        # decode\n",
    "        x_p = self.decode(z_p)\n",
    "        \n",
    "        # fill the labels\n",
    "        b_size = x.size(0)\n",
    "        label = torch.full((b_size,), self.real_label, device=self.device)\n",
    "        \n",
    "        # real\n",
    "        out = self.decide(x.detach(), z.detach())\n",
    "        errD_real = self.bi_loss(out, label)\n",
    "        if update:\n",
    "            errD_real.backward()\n",
    "        \n",
    "        #fake\n",
    "        label.fill_(self.fake_label)\n",
    "        out = self.decide(x_p.detach(), z_p.detach())\n",
    "        errD_fake = self.bi_loss(out, label)\n",
    "        \n",
    "        if update:\n",
    "            errD_fake.backward()\n",
    "            self.optimizerDis.step()\n",
    "        \n",
    "        errD = (errD_real + errD_fake).mean().item()\n",
    "        \n",
    "        # (2) Train Encoder / Decoder\n",
    "        #-------------------------------\n",
    "        # encode\n",
    "        z = self.encode(x)\n",
    "        \n",
    "        # decode\n",
    "        x_p = self.decode(z_p)\n",
    "        \n",
    "        \n",
    "        # real\n",
    "        label.fill_(self.fake_label)\n",
    "        out = self.decide(x, z) \n",
    "        errEnc = self.bi_loss(out, label)\n",
    "        \n",
    "        if update:\n",
    "            errEnc.backward()\n",
    "        \n",
    "        #fake\n",
    "        label.fill_(self.real_label)\n",
    "        out = self.decide(x_p, z_p)\n",
    "        errDec = self.bi_loss(out, label)\n",
    "        \n",
    "        errEncDec = (errEnc + errDec).mean().item()\n",
    "        \n",
    "        # Update Generator\n",
    "        if update:\n",
    "            errDec.backward()\n",
    "            self.optimizerEnc.step()\n",
    "            self.optimizerDec.step()\n",
    "            return x_p\n",
    "        \n",
    "        else:\n",
    "            # Track all relevant losses\n",
    "            tr_data = {}\n",
    "            tr_data[\"ae_loss\"] = ae_loss\n",
    "            tr_data[\"errDis\"] = errD\n",
    "            tr_data[\"errEncDec\"] = errEncDec\n",
    "            \n",
    "            tr_data[\"errD_real\"] = errD_real.mean().item()\n",
    "            tr_data[\"errD_fake\"] = errD_fake.mean().item()\n",
    "            \n",
    "            tr_data[\"errEnc\"] = errEnc.mean().item()\n",
    "            tr_data[\"errDec\"] = errDec.mean().item()\n",
    "\n",
    "            # generate the autoencoder output:\n",
    "            x_r = self.decode(z)\n",
    "\n",
    "            # Return losses and reconstruction data\n",
    "            return x_r, tr_data\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def Creator_RNN_AE(device, args):\n",
    "    \"\"\"\n",
    "    return an instance of the class depending on the mode set in args\n",
    "    \"\"\"\n",
    "    switcher = {\n",
    "        \"ae\": RNN_AE,\n",
    "        \"vae\": RNN_VAE,\n",
    "        \"introvae\": RNN_INTROVAE,\n",
    "        \"bigan\": RNN_BIGAN,\n",
    "    }\n",
    "    # Get the model_creator\n",
    "    model_creator = switcher.get(args.rnn_type, lambda: \"Invalid Model Type\")\n",
    "    return model_creator(device, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 32, 32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if (\n",
    "    torch.cuda.is_available() and args.n_gpu > 0) else \"cpu\")\n",
    "rnn_bigan = RNN_BIGAN(device, args)\n",
    "data = load_test_batch(args)\n",
    "x, tr = rnn_bigan(data, update=False)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dataloader.ipynb.\n",
      "Converted 01_architecture.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_parameters.ipynb.\n",
      "Converted 04_train_loop.ipynb.\n",
      "Converted 10_diagnosis.ipynb.\n",
      "Converted 20_dcgan.ipynb.\n",
      "Converted 21_introvae.ipynb.\n",
      "Converted 22_vqvae.ipynb.\n",
      "Converted 23_bigan.ipynb.\n",
      "Converted 33_rnn_vae.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
