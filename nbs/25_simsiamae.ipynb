{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model.simsiamae\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimSiam Autoencoder\n",
    "\n",
    "> Simple Siamese Loss for Autoencoder based Representation Learning\n",
    "> Based on the paper: https://arxiv.org/abs/2011.10566"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from deeptool.architecture import Encoder, Decoder, DownUpConv\n",
    "from deeptool.abs_model import AbsModel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# deal with varying list and batch sizes:\n",
    "\n",
    "a = list(range(100))\n",
    "ptr = 99\n",
    "batch_size = 4\n",
    "K = 100\n",
    "\n",
    "ind1 = list(range((ptr + batch_size) % K))\n",
    "ind2 = list(range(ptr, K))\n",
    "indexes = ind1 + ind2\n",
    "indexes\n",
    "torch.tensor(np.array([1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "    \"\"\"\n",
    "    The Predictor on top of the encoder network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_dim, mid_dim, out_dim, p_drop=0.5):\n",
    "        \"\"\"init the classifier\"\"\"\n",
    "        super(Predictor, self).__init__()\n",
    "        # reduction block\n",
    "        self.reduce = nn.Sequential(\n",
    "            nn.Linear(in_dim, mid_dim), nn.Dropout(p=p_drop), nn.ReLU(inplace=True),\n",
    "        )\n",
    "        # final block\n",
    "        self.fin_block = nn.Sequential(nn.Linear(mid_dim, out_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"perform forward calculation\"\"\"\n",
    "        # reduce\n",
    "        x = self.reduce(x)\n",
    "        x = self.fin_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class SimSiamAE(AbsModel):\n",
    "    \"\"\"\n",
    "    The SimSiam contains the Autoencoder based Architecture and the modified Pretext task\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device, args):\n",
    "        \"\"\"init the network\"\"\"\n",
    "        super(SimSiamAE, self).__init__(args)\n",
    "        self.device = device  # GPU\n",
    "        self.dim = args.dim   # 2/3 Dimensional input\n",
    "        self.n_z = args.n_z   # Compression\n",
    "        self.ae_mode = args.moco_aemode # inerited from moco\n",
    "\n",
    "        # Encoder\n",
    "        self.enc = Encoder(args, vae_mode=False).to(self.device)  # encoder\n",
    "        \n",
    "        # Predictor\n",
    "        self.pred = Predictor(self.n_z, 2 * self.n_z, self.n_z, p_drop=0.2).to(self.device)\n",
    "        \n",
    "        # optimizers\n",
    "        self.optimizerEnc = optim.SGD(self.enc.parameters(), lr=args.lr)\n",
    "        self.optimizerPred = optim.SGD(self.pred.parameters(), lr=args.lr)\n",
    "        \n",
    "        # override prep and take\n",
    "        self.prep = self.prep_3D if args.dataset_type == \"MRNet\" else self.prep_2D\n",
    "        self.take = self.take_3D if args.dataset_type == \"MRNet\" else self.take_2D\n",
    "        \n",
    "        # init the decoder\n",
    "        self.init_ae(args)\n",
    "    \n",
    "    def init_ae(self, args):\n",
    "        \"\"\"Init the Autoencoder specific parts\"\"\"\n",
    "        # Decoder\n",
    "        self.init_dec(args)\n",
    "        \n",
    "        # loss function\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "    \n",
    "    def init_dec(self, args):\n",
    "        \"\"\"Init a general decoder\"\"\"\n",
    "        self.dec = Decoder(args).to(self.device)  # decoder\n",
    "        self.optimizerDec = optim.Adam(self.dec.parameters(), lr=args.lr)\n",
    "    \n",
    "    def prep_2D(self, data):\n",
    "        return data[0][0]\n",
    "    \n",
    "    def prep_3D(self, data, key=\"img\"):\n",
    "        return data[key]\n",
    "    \n",
    "    def take_2D(self, data):\n",
    "        return data[0][0], data[0][1]\n",
    "    \n",
    "    def take_3D(self, data, key=\"img\"):\n",
    "        return data[key], data[key]\n",
    "\n",
    "    def ae_forward(self, x, update):\n",
    "        \"\"\"\n",
    "        Classic regression part of a normal Autoencoder\n",
    "        \"\"\"\n",
    "        x_r = self.dec(z)\n",
    "        ae_loss = self.mse_loss(x_r, x)\n",
    "        \n",
    "        return x_r, ae_loss\n",
    "    \n",
    "    def D(self, p, z):\n",
    "        \"\"\"\n",
    "        negative cosine similarity\n",
    "        \"\"\"\n",
    "        # stop gradient on z\n",
    "        z = z.detach()\n",
    "        \n",
    "        # normalize\n",
    "        p = nn.functional.normalize(p, dim=1)\n",
    "        z = nn.functional.normalize(z, dim=1)\n",
    "        \n",
    "        return -(p * z).sum(dim=-1).mean()\n",
    "\n",
    "    def forward(self, data, update=True):\n",
    "        \"\"\"\n",
    "        Perform forward computation and update\n",
    "        \"\"\"\n",
    "        # Reset Gradients\n",
    "        self.optimizerEnc.zero_grad()\n",
    "        self.optimizerPred.zero_grad()\n",
    "        self.optimizerDec.zero_grad() if self.ae_mode else None\n",
    "\n",
    "        # 1. Get the augmented data\n",
    "        x1, x2 = self.take(data)\n",
    "\n",
    "        # 2. Send pictures to device\n",
    "        x1 = x1.to(self.device)\n",
    "        x2 = x2.to(self.device)\n",
    "        \n",
    "        # 3. Encode\n",
    "        z1 = self.enc(x1)\n",
    "        z2 = self.enc(x2)\n",
    "        \n",
    "        # 4. Predictor\n",
    "        p1 = self.pred(z1)\n",
    "        p2 = self.pred(z2)\n",
    "        \n",
    "        l_all = 0\n",
    "        l_d = self.D(p1, z2) / 2 + self.D(p2, z1) / 2\n",
    "        l_all += l_d\n",
    "        \n",
    "        # Add the reconstruction loss\n",
    "        if self.ae_mode:\n",
    "            xr = self.dec(z1)\n",
    "            l_ae = self.mse_loss(xr, x1)\n",
    "            l_all += l_ae\n",
    "\n",
    "        # Perform encoder update\n",
    "        if update:\n",
    "            l_all.backward()\n",
    "            \n",
    "            # Encoder and Precitor\n",
    "            self.optimizerEnc.step()\n",
    "            self.optimizerPred.step()\n",
    "            \n",
    "            # Decoder\n",
    "            self.optimizerDec.step() if self.ae_mode else None\n",
    "            return xr.detach()\n",
    "        \n",
    "        else:\n",
    "            tr_data = {\n",
    "                \"loss_ae\": l_ae,\n",
    "                \"loss_D\": l_d,\n",
    "                \"l_all\": l_all,\n",
    "            }\n",
    "            return xr.detach(), tr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
