{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model.mocoae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoCoAE\n",
    "\n",
    "> Momentum Contrast for Autoencoder based Representation Learning\n",
    "> Based and modified from the Github repository of momentum contrast: https://github.com/facebookresearch/moco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from deeptool.architecture import Encoder, Decoder, DownUpConv\n",
    "from deeptool.utils import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 16, 256, 256])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load some test dataset to confirm architecture:\n",
    "from deeptool.parameters import get_all_args\n",
    "from deeptool.dataloader import load_test_batch\n",
    "\n",
    "args = get_all_args()\n",
    "args.model_type = \"rnnvae\"\n",
    "args.batch_size = 5\n",
    "args.track = False\n",
    "batch = load_test_batch(args)\n",
    "batch[\"img\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class MoCoAE(nn.Module):\n",
    "    \"\"\"\n",
    "    The MoCoAE contains the Autoencoder based Architecture and the modified Pretext task\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device, args):\n",
    "        \"\"\"init the network\"\"\"\n",
    "        super(MoCoAE, self).__init__()\n",
    "        self.device = device  # GPU\n",
    "        self.dim = args.dim  # 2/3 Dimensional input\n",
    "        self.n_z = args.n_z  # Compression\n",
    "\n",
    "        ### MoCo specific args\n",
    "        self.K = args.moco_K  # limit of the queue\n",
    "        self.tau = args.moco_tau  # temperature\n",
    "        self.m = args.moco_m  # momentum\n",
    "\n",
    "        # Encoder\n",
    "        self.enc_q = Encoder(args, vae_mode=False).to(self.device)  # query encoder\n",
    "        self.enc_k = Encoder(args, vae_mode=False).to(self.device)  # key encoder\n",
    "\n",
    "        # Decoder\n",
    "        self.dec_q = Decoder(args).to(self.device)  # query decoder\n",
    "        self.dec_k = Decoder(args).to(self.device)  # key decoder\n",
    "\n",
    "        # set the params of the knetwork to be equal q network:\n",
    "        copy_q2k_params(self.enc_q, self.enc_k)\n",
    "        copy_q2k_params(self.dec_q, self.dec_k)\n",
    "\n",
    "        # Initialise the randomised Queues for Momentum Contrastive Learning\n",
    "        self.register_queue(\"enc_queue\")\n",
    "        self.register_queue(\"dec_queue\")\n",
    "\n",
    "        # Save the pointer position as well\n",
    "        self.register_buffer(\"ptr_enc\", torch.zeros(1, dtype=torch.long).to(self.device))\n",
    "        self.register_buffer(\"ptr_dec\", torch.zeros(1, dtype=torch.long).to(self.device))\n",
    "\n",
    "        # optimizers\n",
    "        self.optimizerEnc = optim.Adam(self.enc_q.parameters(), lr=args.lr)\n",
    "        self.optimizerDec = optim.Adam(self.dec_q.parameters(), lr=args.lr)\n",
    "\n",
    "        # Setup the tracker to visualize the progress\n",
    "        if args.track:\n",
    "            self.tracker = Tracker(args)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def register_queue(self, name: str):\n",
    "        \"\"\"\n",
    "        Register the queue as a buffer with no parameters in the state dict\n",
    "        \"\"\"\n",
    "        # create the queue\n",
    "        self.register_buffer(name, torch.randn(self.n_z, self.K).to(self.device))\n",
    "        setattr(self, name, nn.functional.normalize(getattr(self, name), dim=0))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def watch_progress(self, test_data, iteration):\n",
    "        \"\"\"\n",
    "        Outsourced to Tracker\n",
    "        \"\"\"\n",
    "        self.tracker.track_progress(self, test_data, iteration)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys, mode=\"enc\"):\n",
    "        \"\"\"\n",
    "        Update the Queue and Pointer ->\n",
    "        available in mode 'enc' and 'dec'\n",
    "        \"\"\"\n",
    "        # gather keys before updating queue\n",
    "        batch_size = keys.shape[0]\n",
    "\n",
    "        ptr = int(getattr(self, f\"ptr_{mode}\"))\n",
    "\n",
    "        # replace the keys at ptr (dequeue and enqueue)\n",
    "        if mode == \"enc\":\n",
    "            self.enc_queue[:, ptr : ptr + batch_size] = keys.T\n",
    "            ptr = (ptr + batch_size) % self.K\n",
    "            self.ptr_enc[0] = ptr\n",
    "\n",
    "        # mode is 'dec'\n",
    "        else:\n",
    "            self.dec_queue[:, ptr : ptr + batch_size] = keys.T\n",
    "            ptr = (ptr + batch_size) % self.K\n",
    "            self.ptr_dec[0] = ptr\n",
    "\n",
    "    def forward(self, data, update=True):\n",
    "        \"\"\"\n",
    "        Perform forward computaion and update\n",
    "        \"\"\"\n",
    "        # Reset Gradients\n",
    "        self.optimizerEnc.zero_grad()\n",
    "        self.optimizerDec.zero_grad()\n",
    "\n",
    "        # 1. Send data to device\n",
    "        x = data[\"img\"]\n",
    "\n",
    "        # 2. further we will apply additional augmentation to the picture!\n",
    "        x_q = aug(x).to(self.device)\n",
    "        x_k = aug(x).to(self.device)\n",
    "\n",
    "        # 3. Encode\n",
    "        q = self.enc_q(x_q)\n",
    "        q = nn.functional.normalize(q, dim=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            k = self.enc_k(x_k)\n",
    "            k = nn.functional.normalize(k, dim=1)\n",
    "        \n",
    "        # Get the InfoNCE loss:\n",
    "        loss_enc = MomentumContrastiveLoss(k, q, self.enc_queue, self.tau, device=self.device)\n",
    "\n",
    "        # Perform encoder update\n",
    "        if update: \n",
    "            loss_enc.backward()\n",
    "\n",
    "            # update the Query Encoder\n",
    "            self.optimizerEnc.step()\n",
    "\n",
    "            # update the Key Encoder with Momentum update\n",
    "            momentum_update(self.enc_q, self.enc_k, self.m)\n",
    "\n",
    "        # append keys to the queue\n",
    "        self._dequeue_and_enqueue(k, mode=\"enc\")\n",
    "\n",
    "        # 4. Decode\n",
    "        x_qq = self.dec_q(q.detach())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x_kk = self.dec_k(k)\n",
    "\n",
    "        # 5. Encode again using the k-network to focus on decoder only!:\n",
    "        qq = self.enc_k(x_qq)\n",
    "        qq = nn.functional.normalize(qq, dim=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            kk = self.enc_k(x_kk).detach()\n",
    "            kk = nn.functional.normalize(kk, dim=1)\n",
    "        \n",
    "        # Get the InfoNCE loss:\n",
    "        loss_dec = MomentumContrastiveLoss(kk, qq, self.dec_queue, self.tau, device=self.device)\n",
    "\n",
    "        # perform decoder update\n",
    "        if update:\n",
    "            loss_dec.backward()\n",
    "\n",
    "            # update the Query Decoder\n",
    "            self.optimizerDec.step()\n",
    "\n",
    "            # update the Key Decoder with Momentum update\n",
    "            momentum_update(self.dec_q, self.dec_k, self.m)\n",
    "\n",
    "        # append keys to the queue\n",
    "        self._dequeue_and_enqueue(kk, mode=\"dec\")\n",
    "\n",
    "        if update:\n",
    "            return x_kk\n",
    "\n",
    "        else:\n",
    "            tr_data = {\n",
    "                \"loss_enc\": loss_enc.item(),\n",
    "                \"loss_dec\": loss_dec.item(),\n",
    "            }\n",
    "            return x_kk, tr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions handling the queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@torch.no_grad()\n",
    "def concat_all_gather(tensor):\n",
    "    \"\"\"\n",
    "    Performs all_gather operation on the provided tensors.\n",
    "    *** Warning ***: torch.distributed.all_gather has no gradient.\n",
    "    \"\"\"\n",
    "    tensors_gather = [\n",
    "        torch.ones_like(tensor) for _ in range(torch.distributed.get_world_size())\n",
    "    ]\n",
    "    torch.distributed.all_gather(tensors_gather, tensor, async_op=False)\n",
    "\n",
    "    output = torch.cat(tensors_gather, dim=0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions Handling the K and Q Network updates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@torch.no_grad()\n",
    "def copy_q2k_params(Q_network: nn.Module, K_network: nn.Module):\n",
    "    \"\"\"\n",
    "    Helper function to Copy parameters from Network Q to network K.\n",
    "    Further deactive gradient computation on k\n",
    "    \"\"\"\n",
    "    for param_q, param_k in zip(Q_network.parameters(), K_network.parameters()):\n",
    "        param_k.data.copy_(param_q.data)  # initialize\n",
    "        param_k.requires_grad = False  # not updated by gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@torch.no_grad()\n",
    "def momentum_update(Q_network: nn.Module, K_network: nn.Module, m: float):\n",
    "    \"\"\"\n",
    "    Momentum update of the key network based on the query network\n",
    "    \"\"\"\n",
    "    for param_q, param_k in zip(Q_network.parameters(), K_network.parameters()):\n",
    "        param_k.data = param_k.data * m + param_q.data * (1.0 - m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def aug(x):\n",
    "    \"\"\"perform random data augmentation on an image batch\"\"\"\n",
    "    # ToDo\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum Contrastive Loss:\n",
    "\n",
    "$ Loss = -\\log \\left( \\frac{ \\exp{ \\frac{q \\cdot k_+}{\\tau} } }{\\sum_{i=0}^{n}{\\exp{\\frac{q \\cdot k_i}{\\tau}  }} } \\right) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def MomentumContrastiveLoss(k, q, queue, tau, device):\n",
    "    \"\"\"\n",
    "    Calculate the loss of the network depending on the current key(k), the query(q)\n",
    "    and the overall queue(queue)\n",
    "    We follow the suggestion of the paper, Algorithm 1:\n",
    "    https://arxiv.org/pdf/1911.05722.pdf\n",
    "    \"\"\"\n",
    "    N, C = q.shape\n",
    "    K = k.shape[1]\n",
    "\n",
    "    # positive logits: Nx1\n",
    "    l_pos = torch.einsum(\"nc,nc->n\", [q, k]).unsqueeze(-1)\n",
    "\n",
    "    # negative logits: NxK\n",
    "    l_neg = torch.einsum(\"nc,ck->nk\", [q, queue.clone().detach()])\n",
    "\n",
    "    # logits: Nx(1+K) with temperature\n",
    "    logits = torch.cat([l_pos, l_neg], dim=1) / tau\n",
    "\n",
    "    # positive key indicators\n",
    "    labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n",
    "\n",
    "    # calculate the crossentropyloss\n",
    "    loss = ce_loss(logits, labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(input.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dataloader.ipynb.\n",
      "Converted 01_architecture.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_parameters.ipynb.\n",
      "Converted 04_train_loop.ipynb.\n",
      "Converted 10_diagnosis.ipynb.\n",
      "Converted 20_dcgan.ipynb.\n",
      "Converted 21_introvae.ipynb.\n",
      "Converted 22_vqvae.ipynb.\n",
      "Converted 23_bigan.ipynb.\n",
      "Converted 24_mocoae.ipynb.\n",
      "Converted 33_rnn_vae.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda26b20a7b2fd84e458f56623d2b65063b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
