{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model.mocoae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoCoAE\n",
    "\n",
    "> Momentum Contrast for Autoencoder based Representation Learning\n",
    "> Based and modified from the Github repository of momentum contrast: https://github.com/facebookresearch/moco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img\\mocoae.PNG\" alt=\"Drawing\" style=\"width: 700px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from deeptool.architecture import Encoder, Decoder, DownUpConv\n",
    "from deeptool.abs_model import AbsModel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# deal with varying list and batch sizes:\n",
    "\n",
    "a = list(range(100))\n",
    "ptr = 99\n",
    "batch_size = 4\n",
    "K = 100\n",
    "\n",
    "ind1 = list(range((ptr + batch_size) % K))\n",
    "ind2 = list(range(ptr, K))\n",
    "indexes = ind1 + ind2\n",
    "indexes\n",
    "torch.tensor(np.array([1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class MoCoAE(AbsModel):\n",
    "    \"\"\"\n",
    "    The MoCoAE contains the Autoencoder based Architecture and the modified Pretext task\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device, args):\n",
    "        \"\"\"init the network\"\"\"\n",
    "        super(MoCoAE, self).__init__(args)\n",
    "        self.device = device  # GPU\n",
    "        self.dim = args.dim  # 2/3 Dimensional input\n",
    "        self.n_z = args.n_z  # Compression\n",
    "\n",
    "        ### MoCo specific args\n",
    "        self.K = args.moco_K  # limit of the queue\n",
    "        self.tau = args.moco_tau  # temperature\n",
    "        self.m = args.moco_m  # momentum\n",
    "\n",
    "        # Modes:\n",
    "        self.ae_mode = args.moco_aemode\n",
    "        self.gan_mode = args.moco_ganmode\n",
    "\n",
    "        # Encoder\n",
    "        self.enc_q = Encoder(args, vae_mode=False).to(self.device)  # query encoder\n",
    "        self.enc_k = Encoder(args, vae_mode=False).to(self.device)  # key encoder\n",
    "        \n",
    "        #balancing parameter for MOCO\n",
    "        self.W = nn.Parameter(torch.randn([args.n_z, args.n_z], device=self.device))\n",
    "\n",
    "        # set the params of the k-network to be equal to the q-network:\n",
    "        copy_q2k_params(self.enc_q, self.enc_k)\n",
    "\n",
    "        # Initialise the randomised Queues for Momentum Contrastive Learning\n",
    "        self.register_queue(\"enc_queue\")\n",
    "        \n",
    "        # Save the pointer position as well\n",
    "        self.register_buffer(\n",
    "            \"ptr_enc\", torch.zeros(1, dtype=torch.long).to(self.device)\n",
    "        )\n",
    "\n",
    "        # optimizers\n",
    "        self.optimizerEnc = optim.Adam(self.enc_q.parameters(), lr=args.lr)\n",
    "        self.optimizerW = optim.Adam([self.W], lr=args.lr)\n",
    "        \n",
    "        # Autoencoder init?\n",
    "        self.init_ae(args) if self.ae_mode else None       \n",
    "        \n",
    "        # GAN init?\n",
    "        self.init_gan(args) if self.gan_mode else None            \n",
    "        \n",
    "        # override prep and take\n",
    "        self.prep = self.prep_3D if args.dataset_type == \"MRNet\" else self.prep_2D\n",
    "        self.take = self.take_3D if args.dataset_type == \"MRNet\" else self.take_2D\n",
    "    \n",
    "    def init_ae(self, args):\n",
    "        \"\"\"Init the Autoencoder specific parts\"\"\"\n",
    "        # Decoder\n",
    "        self.init_dec(args)\n",
    "        \n",
    "        # loss function\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        \n",
    "    def init_gan(self, args):\n",
    "        \"\"\"Init the GAN specific parts\"\"\"\n",
    "        # Head of the Discriminator:\n",
    "        self.gan_head = nn.Sequential(\n",
    "            nn.Linear(args.n_z, args.n_z),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(args.n_z, 1),\n",
    "            nn.Sigmoid(),\n",
    "        ).to(self.device)\n",
    "        self.optimizerGan = optim.Adam(self.gan_head.parameters(), lr=args.lr)\n",
    "        \n",
    "        # Generator -> Decoder\n",
    "        self.init_dec(args)\n",
    "        \n",
    "        # labels\n",
    "        self.real_label = 1\n",
    "        self.fake_label = 0\n",
    "        \n",
    "        # loss function\n",
    "        self.gan_loss = nn.BCELoss()\n",
    "    \n",
    "    def init_dec(self, args):\n",
    "        \"\"\"Init a general decoder\"\"\"\n",
    "        self.dec = Decoder(args).to(self.device)  # decoder\n",
    "        self.optimizerDec = optim.Adam(self.dec.parameters(), lr=args.lr)\n",
    "    \n",
    "    def prep_2D(self, data):\n",
    "        return data[0][0]\n",
    "    \n",
    "    def prep_3D(self, data, key=\"img\"):\n",
    "        return data[key]\n",
    "    \n",
    "    def take_2D(self, data):\n",
    "        return data[0][0], data[0][1]\n",
    "    \n",
    "    def take_3D(self, data, key=\"img\"):\n",
    "        return data[key], data[key]\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def register_queue(self, name: str):\n",
    "        \"\"\"\n",
    "        Register the queue as a buffer with no parameters in the state dict\n",
    "        \"\"\"\n",
    "        # create the queue\n",
    "        self.register_buffer(name, torch.randn(self.n_z, self.K).to(self.device))\n",
    "        setattr(self, name, nn.functional.normalize(getattr(self, name), dim=0))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "        \"\"\"\n",
    "        Update the Queue and Pointer ->\n",
    "        available in mode 'enc' and 'dec'\n",
    "        \"\"\"\n",
    "        # gather keys before updating queue\n",
    "        batch_size = keys.shape[0]\n",
    "\n",
    "        ptr = int(getattr(self, \"ptr_enc\"))\n",
    "        indixes = list(range(ptr, ptr + batch_size))\n",
    "\n",
    "        if ptr + batch_size > self.K:\n",
    "            ind1 = list(range((ptr + batch_size) % self.K))\n",
    "            ind2 = list(range(ptr, self.K))\n",
    "            indixes = ind1 + ind2\n",
    "\n",
    "        # replace the keys at ptr (dequeue and enqueue)\n",
    "        self.enc_queue[:, indixes] = keys.T\n",
    "        ptr = (ptr + batch_size) % self.K\n",
    "        self.ptr_enc[0] = ptr\n",
    "\n",
    "    def ae_forward(self, x, update):\n",
    "        \"\"\"\n",
    "        Classic regression part of a normal Autoencoder\n",
    "        \"\"\"\n",
    "        self.optimizerEnc.zero_grad()\n",
    "   \n",
    "        z = self.enc_q(x)\n",
    "        z = nn.functional.normalize(z, dim=1)\n",
    "        x_r = self.dec(z)\n",
    "        \n",
    "        # loss\n",
    "        if self.ae_mode:\n",
    "            ae_loss = self.mse_loss(x_r, x)\n",
    "            ae_loss.backward(retain_graph=True) if update else None\n",
    "            ae_loss = ae_loss.item()\n",
    "        else:\n",
    "            ae_loss = 0\n",
    "        \n",
    "        return x_r, ae_loss\n",
    "    \n",
    "    def gan_forward(self, x_q, k, update):\n",
    "        \"\"\"\n",
    "        Gan part taking the original image and the key to determine between true / fake\n",
    "        \"\"\"\n",
    "        b_size = k.size(0)\n",
    "        self.optimizerGan.zero_grad()\n",
    "        \n",
    "        ############################\n",
    "        # (1) Discriminator Training\n",
    "        ###########################\n",
    "        \n",
    "        # true\n",
    "        label = torch.full((b_size,), self.real_label, device=self.device, dtype=torch.float32)\n",
    "        q_real = self.enc_q(x_q)\n",
    "        output = self.gan_head(q_real).view(-1)\n",
    "        d_loss_real = self.gan_loss(output, label)\n",
    "        d_loss_real.backward() if update else None\n",
    "        \n",
    "        # fake\n",
    "        label.fill_(self.fake_label)\n",
    "        x_a = self.dec(k.detach())\n",
    "        q_fake = self.enc_q(x_a.detach())\n",
    "        output = self.gan_head(q_fake).view(-1)\n",
    "        d_loss_fake = self.gan_loss(output, label)\n",
    "        d_loss_fake.backward() if update else None\n",
    "        d_loss = d_loss_fake.item() + d_loss_real.item()\n",
    "        \n",
    "        # update now before adding wrong gradients!\n",
    "        if update:\n",
    "            self.optimizerEnc.step()\n",
    "            self.optimizerGan.step()\n",
    "        \n",
    "        ############################\n",
    "        # (2) Generator Training\n",
    "        ###########################\n",
    "        self.optimizerDec.zero_grad()\n",
    "        \n",
    "        # fake\n",
    "        label.fill_(self.real_label)\n",
    "        x_a = self.dec(k.detach())\n",
    "        q_fake = self.enc_q(x_q)\n",
    "        output = self.gan_head(q_fake).view(-1)\n",
    "        g_loss = self.gan_loss(output, label)\n",
    "        g_loss.backward() if update else None\n",
    "        g_loss = g_loss.item()\n",
    "                \n",
    "        return x_a, d_loss, g_loss\n",
    "        \n",
    "\n",
    "    def forward(self, data, update=True):\n",
    "        \"\"\"\n",
    "        Perform forward computation and update\n",
    "        \"\"\"\n",
    "        # Reset Gradients\n",
    "        self.optimizerEnc.zero_grad()\n",
    "        self.optimizerW.zero_grad()\n",
    "        self.optimizerDec.zero_grad() if self.gan_mode or self.ae_mode else None\n",
    "\n",
    "        # 1. Get the augmented data\n",
    "        x_q, x_k = self.take(data)\n",
    "\n",
    "        # 2. Send pictures to device\n",
    "        x_q = x_q.to(self.device)\n",
    "        x_k = x_k.to(self.device)\n",
    "        \n",
    "        # 3. Encode with Momentum Encoder\n",
    "        with torch.no_grad():\n",
    "            k = self.enc_k(x_k)\n",
    "            k = nn.functional.normalize(k, dim=1)\n",
    "\n",
    "        # Optinonal: AE part if on\n",
    "        loss_ae = 0\n",
    "        if self.ae_mode or self.gan_mode:\n",
    "            x_q, loss_ae = self.ae_forward(x_k, update)\n",
    "\n",
    "        # 3. Encode the 'augmented picture'\n",
    "        q = self.enc_q(x_q)\n",
    "        q = nn.functional.normalize(q, dim=1)\n",
    "        \n",
    "        # Get the InfoNCE loss:\n",
    "        loss_InfoNCE = MomentumContrastiveLoss(\n",
    "            k, self.W, q, self.enc_queue, device=self.device, tau=self.tau\n",
    "        )\n",
    "        loss_InfoNCE.backward() if update else None\n",
    "        loss_InfoNCE = loss_InfoNCE.item()\n",
    "        \n",
    "        # append keys to the queue\n",
    "        self._dequeue_and_enqueue(k)\n",
    "\n",
    "        # Perform encoder update\n",
    "        if update:\n",
    "            # Encoder\n",
    "            self.optimizerEnc.step()\n",
    "            momentum_update(self.enc_q, self.enc_k, self.m[0])\n",
    "            \n",
    "            # Decoder\n",
    "            self.optimizerDec.step() if self.gan_mode or self.ae_mode else None\n",
    "            \n",
    "            # W\n",
    "            self.optimizerW.step() if self.gan_mode or self.ae_mode else None\n",
    "        \n",
    "        # Optional: GAN part if on\n",
    "        d_loss, g_loss = 0, 0\n",
    "        if self.gan_mode:\n",
    "            x_q, d_loss, g_loss = self.gan_forward(x_q.detach(), q.detach(), update)\n",
    "\n",
    "        if update:\n",
    "            return x_q.detach()\n",
    "            \n",
    "        else:\n",
    "            tr_data = {\n",
    "                \"loss_ae\": loss_ae,\n",
    "                \"loss_InfoNCE\": loss_InfoNCE,\n",
    "                \"d_loss\": d_loss,\n",
    "                \"g_loss\": g_loss,\n",
    "            }\n",
    "            return x_q.detach(), tr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions handling the queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@torch.no_grad()\n",
    "def concat_all_gather(tensor):\n",
    "    \"\"\"\n",
    "    Performs all_gather operation on the provided tensors.\n",
    "    *** Warning ***: torch.distributed.all_gather has no gradient.\n",
    "    \"\"\"\n",
    "    tensors_gather = [\n",
    "        torch.ones_like(tensor) for _ in range(torch.distributed.get_world_size())\n",
    "    ]\n",
    "    torch.distributed.all_gather(tensors_gather, tensor, async_op=False)\n",
    "\n",
    "    output = torch.cat(tensors_gather, dim=0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions Handling the K and Q Network updates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@torch.no_grad()\n",
    "def copy_q2k_params(Q_network: nn.Module, K_network: nn.Module):\n",
    "    \"\"\"\n",
    "    Helper function to Copy parameters from Network Q to network K.\n",
    "    Further deactive gradient computation on k\n",
    "    \"\"\"\n",
    "    for param_q, param_k in zip(Q_network.parameters(), K_network.parameters()):\n",
    "        param_k.data.copy_(param_q.data) # initialize\n",
    "        param_k.requires_grad = False # not updated by gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@torch.no_grad()\n",
    "def momentum_update(Q_network: nn.Module, K_network: nn.Module, m: float):\n",
    "    \"\"\"Momentum update of the key network based on the query network\"\"\"\n",
    "    for param_q, param_k in zip(Q_network.parameters(), K_network.parameters()):\n",
    "        param_k.data = param_k.data * m + param_q.data * (1.0 - m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum Contrastive Loss:\n",
    "\n",
    "$ Loss = -\\log \\left( \\frac{ \\exp{ \\frac{q \\cdot k_+}{\\tau} } }{\\sum_{i=0}^{n}{\\exp{\\frac{q \\cdot k_i}{\\tau}  }} } \\right) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def MomentumContrastiveLoss(k, W, q, queue, device, tau=1):\n",
    "    \"\"\"\n",
    "    Calculate the loss of the network depending on the current key(k), the query(q)\n",
    "    and the overall queue(queue)\n",
    "    We follow the suggestion of the paper, Algorithm 1:\n",
    "    https://arxiv.org/pdf/1911.05722.pdf\n",
    "    \"\"\"\n",
    "    # positive logits: Nx1\n",
    "    l_pos = torch.einsum(\"nc,cc,nc->n\", [q, W, k]).unsqueeze(-1)\n",
    "\n",
    "    # negative logits: NxK\n",
    "    l_neg = torch.einsum(\"nc,cc,ck->nk\", [q, W, queue.clone().detach()])\n",
    "\n",
    "    # logits: Nx(1+K) with temperature\n",
    "    logits = torch.cat([l_pos, l_neg], dim=1) / tau\n",
    "    \n",
    "    # substract max for stability\n",
    "    logits.sub_(torch.max(logits, axis=1).values.unsqueeze(1))\n",
    "\n",
    "    # positive key indicators\n",
    "    labels = torch.zeros(logits.shape[0], dtype=torch.long).to(device)\n",
    "\n",
    "    # calculate the crossentropyloss\n",
    "    loss = ce_loss(logits, labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# Loss function tests\n",
    "dim_n, dim_c, dim_k = 2, 10, 100\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "q = torch.randn([dim_n, dim_c])\n",
    "k = torch.randn([dim_n, dim_c])\n",
    "W = nn.Parameter(torch.randn([dim_c, dim_c]))\n",
    "\n",
    "queue = torch.randn([dim_c, dim_k])\n",
    "loss = MomentumContrastiveLoss(k, W, q, queue, device)\n",
    "\n",
    "optim.Adam([W], lr=0.0002)\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from deeptool.train_loop import test_one_batch\n",
    "from deeptool.parameters import get_all_args, compat_args\n",
    "PIC_SIZE = 32\n",
    "\n",
    "args = get_all_args()\n",
    "args.pic_size = PIC_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-Type: mocoae\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# 3dim test -> ae\n",
    "args = get_all_args()\n",
    "args.pic_size = PIC_SIZE\n",
    "args.model_type = \"mocoae\"\n",
    "args.dim = 3\n",
    "args.moco_aemode = True\n",
    "args.moco_ganmode = False\n",
    "\n",
    "args = compat_args(args)\n",
    "test_one_batch(args) # 3d, ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-Type: mocoae\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# 2dim test -> ae\n",
    "args = get_all_args()\n",
    "args.pic_size = PIC_SIZE\n",
    "args.model_type = \"mocoae\"\n",
    "args.dim = 2\n",
    "args.moco_aemode = True\n",
    "args.moco_ganmode = False\n",
    "\n",
    "args = compat_args(args)\n",
    "test_one_batch(args) # 2d, ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-Type: mocoae\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# 3dim test -> gan\n",
    "args = get_all_args()\n",
    "args.pic_size = PIC_SIZE\n",
    "args.model_type = \"mocoae\"\n",
    "args.dim = 3\n",
    "args.moco_aemode = False\n",
    "args.moco_ganmode = True\n",
    "\n",
    "args = compat_args(args)\n",
    "test_one_batch(args) # 3d, gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-Type: mocoae\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# 3 dim test -> ae + gan simultaneous\n",
    "args = get_all_args()\n",
    "args.pic_size = PIC_SIZE\n",
    "args.model_type = \"mocoae\"\n",
    "args.dim = 3\n",
    "args.moco_aemode = True\n",
    "args.moco_ganmode = False\n",
    "\n",
    "args = compat_args(args)\n",
    "test_one_batch(args) # 3d, ae + gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dataloader.ipynb.\n",
      "Converted 01_architecture.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_parameters.ipynb.\n",
      "Converted 04_train_loop.ipynb.\n",
      "Converted 05_abstract_model.ipynb.\n",
      "Converted 10_diagnosis.ipynb.\n",
      "Converted 20_dcgan.ipynb.\n",
      "Converted 21_introvae.ipynb.\n",
      "Converted 22_vqvae.ipynb.\n",
      "Converted 23_bigan.ipynb.\n",
      "Converted 24_mocoae.ipynb.\n",
      "Converted 33_rnn_vae.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
