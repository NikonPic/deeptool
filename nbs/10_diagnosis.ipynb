{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnosis\n",
    "\n",
    "> Structure for performing Diagnosis for 3D Datasets\n",
    "\n",
    "<img src=\"../img/diagnosis.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "     \n",
    "\n",
    "     \n",
    "https://stanfordmlgroup.github.io/projects/mrnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import pdb\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from torchvision import models\n",
    "from deeptool.utils import Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Final Classification Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Classify(nn.Module):\n",
    "    \"\"\"\n",
    "    The Classifier on top of the triplenet network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_dim, mid_dim, out_dim, p_drop=0.5):\n",
    "        \"\"\"init the classifier\"\"\"\n",
    "        super(Classify, self).__init__()\n",
    "        # reduction block\n",
    "        self.reduce = nn.Sequential(\n",
    "            nn.Linear(in_dim, mid_dim),\n",
    "            nn.Dropout(p=p_drop),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        # final block\n",
    "        self.fin_block = nn.Sequential(\n",
    "            nn.Linear(mid_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"perform forward calculation\"\"\"\n",
    "        # reduce\n",
    "        x = self.reduce(x)\n",
    "        x = self.fin_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed extension: Maintaining the spatial Relation using Recurrence\n",
    "\n",
    "<img src=\"../img/diagnosis_rnn.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Classify_RNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The Classifier on top of the triplenet network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device, input_size, hidden_size, n_layers=1):\n",
    "        \"\"\"init the classifier\"\"\"\n",
    "        super(Classify_RNN, self).__init__()\n",
    "        self.device = device\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, n_layers).to(self.device)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        \"\"\"create zeros for hidden layer\"\"\"\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"perform forward calculation\"\"\"\n",
    "        x = x.view(-1, 1, self.input_size)\n",
    "        # create hidden dimension\n",
    "        hidden = self.init_hidden()\n",
    "        # apply GRU\n",
    "        _, hidden = self.gru(x, hidden)\n",
    "        # use hidden for final linear layer (equal to last output)\n",
    "        return hidden.view(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Complete Network with Backbone and Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class TripleMRNet(nn.Module):\n",
    "    \"\"\"\n",
    "    adapted from https://github.com/yashbhalgat/MRNet-Competition\n",
    "    with the knowledge of: https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002699\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device, args, train_data=None, backbone=\"resnet18\", training=True, document=True):\n",
    "        super(TripleMRNet, self).__init__()\n",
    "\n",
    "        # general defines\n",
    "        self.device = device\n",
    "        self.backbone = args.mrnet_backbone\n",
    "        self.y_labels = args.classes\n",
    "        self.y_len = len(self.y_labels)\n",
    "        self.naming = args.perspectives\n",
    "\n",
    "        # depending on whether train_data is specified\n",
    "        if train_data == None:\n",
    "            self.weights = {}\n",
    "            self.weights['abn'] = [0.81, 0.19]\n",
    "            self.weights['acl'] = [0.23, 0.77]\n",
    "            self.weights['men'] = [0.43, 0.57]\n",
    "        else:\n",
    "            self.weights = train_data.weights\n",
    "\n",
    "        # picture center cropping to 224 resolution\n",
    "        self.pic_size = 224\n",
    "        self.pad = int((args.pic_size - self.pic_size) / 2)\n",
    "        self.factor = 1  # 1130 / 208  # inverse factor\n",
    "\n",
    "        # internal count for updating\n",
    "        self.int_count = 0\n",
    "        self.batch_update = args.mrnet_batch_update\n",
    "        self.label_smoothing = args.mrnet_label_smoothing\n",
    "\n",
    "        # Setup the tracker to visualize the progress\n",
    "        if args.track:\n",
    "            self.tracker = Tracker(args)\n",
    "\n",
    "        # average together\n",
    "        self.rnn_gap = args.mrnet_rnn_gap\n",
    "        self.hidden_dim = args.mrnet_hidden_dim\n",
    "\n",
    "        # define whether to use one network or multiple ones\n",
    "        self.single_stream = args.mrnet_singlestream\n",
    "\n",
    "        # build backbone networks\n",
    "        self.axial_net = self.build_backbone(training)\n",
    "        self.sagit_net = self.build_backbone(training)\n",
    "        self.coron_net = self.build_backbone(training)\n",
    "\n",
    "        # build gap and classifier\n",
    "        # apply average pooling\n",
    "        self.gap_axial = nn.AdaptiveAvgPool2d(1).to(self.device)\n",
    "        self.gap_sagit = nn.AdaptiveAvgPool2d(1).to(self.device)\n",
    "        self.gap_coron = nn.AdaptiveAvgPool2d(1).to(self.device)\n",
    "\n",
    "        if self.rnn_gap:\n",
    "            # only for the avergae case\n",
    "            if self.backbone in (\"resnet18\", \"vgg\", \"squeeze\"):\n",
    "                self.input_rnn = 512\n",
    "            else:\n",
    "                self.input_rnn = 256\n",
    "\n",
    "            # the RNN gapping\n",
    "            self.max_axial = Classify_RNN(\n",
    "                self.device, self.input_rnn, self.hidden_dim)\n",
    "            self.max_sagit = Classify_RNN(\n",
    "                self.device, self.input_rnn, self.hidden_dim)\n",
    "            self.max_coron = Classify_RNN(\n",
    "                self.device, self.input_rnn, self.hidden_dim)\n",
    "\n",
    "            # add a classifier at the end\n",
    "            #self.classifier = nn.Sequential(nn.Linear(3 * self.hidden_dim, self.y_len))\n",
    "            self.classifier = Classify(\n",
    "                3*self.hidden_dim, self.hidden_dim, self.y_len)\n",
    "\n",
    "        else:\n",
    "            # only for the avergae case\n",
    "            if self.backbone in (\"resnet18\", \"vgg\", \"squeeze\"):\n",
    "                self.classifier = Classify(\n",
    "                    3*512, self.hidden_dim, self.y_len).to(self.device)\n",
    "            elif self.backbone == \"alexnet\":\n",
    "                self.classifier = Classify(\n",
    "                    3*256, self.hidden_dim, self.y_len).to(self.device)\n",
    "\n",
    "        # fineal sigmoid layer\n",
    "        self.sigmoid = nn.Sigmoid().to(self.device)\n",
    "\n",
    "        # redefine if single stream\n",
    "        if self.single_stream:\n",
    "            # make them all reference the same network\n",
    "            self.sagit_net = self.axial_net\n",
    "            self.coron_net = self.axial_net\n",
    "\n",
    "            if self.rnn_gap:\n",
    "                self.max_sagit = self.max_axial\n",
    "                self.max_coron = self.max_axial\n",
    "\n",
    "        self.classifier.to(self.device)\n",
    "        self.axial_net.to(self.device)\n",
    "        self.coron_net.to(self.device)\n",
    "        self.sagit_net.to(self.device)\n",
    "\n",
    "        # define optimizer\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=args.lr)\n",
    "\n",
    "    def build_backbone(self, training):\n",
    "        \"\"\"\n",
    "        Builds the desired backbone\n",
    "        \"\"\"\n",
    "        if self.backbone == \"resnet18\":\n",
    "            resnet = models.resnet18(pretrained=training)\n",
    "            modules = list(resnet.children())[:-1]\n",
    "            local_net = nn.Sequential(*modules)\n",
    "            for param in local_net.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        elif self.backbone == \"alexnet\":\n",
    "            local_net = models.alexnet(pretrained=training)\n",
    "            local_net = local_net.features\n",
    "\n",
    "        elif self.backbone == \"vgg\":\n",
    "            local_net = models.vgg11(pretrained=training)\n",
    "            local_net = local_net.features\n",
    "\n",
    "        elif self.backbone == \"squeeze\":\n",
    "            local_net = models.squeezenet1_1(pretrained=training)\n",
    "            local_net = local_net.features\n",
    "\n",
    "        return local_net\n",
    "\n",
    "    def weighted_loss(self, prediction, target, cl):\n",
    "        \"\"\"\n",
    "        Calculate the weighted loss with label smoothing \n",
    "        \"\"\"\n",
    "        # determin the weights\n",
    "        weights_npy = np.array(\n",
    "            [self.weights[cl][int(target)]])\n",
    "        weights_tensor = torch.FloatTensor(weights_npy)\n",
    "        weights_tensor = weights_tensor.to(self.device)[0]\n",
    "\n",
    "        # smooth the labels\n",
    "        if self.label_smoothing > 0:\n",
    "            target = target.add(self.label_smoothing).div(2)\n",
    "\n",
    "        # calculate binary cross entropy\n",
    "        loss = F.binary_cross_entropy_with_logits(\n",
    "            prediction, target, weight=Variable(weights_tensor))\n",
    "        return loss\n",
    "\n",
    "    def watch_progress(self, valid_loader, iteration):\n",
    "        \"\"\"Outsourced to Tracker\"\"\"\n",
    "        self.tracker.get_accuracy(self, valid_loader, iteration)\n",
    "\n",
    "    def get_input_image(self, data):\n",
    "        \"\"\"\n",
    "        take the input from the stack and give the single volumes\n",
    "        \"\"\"\n",
    "        # get the three volumes from the dictionary\n",
    "        # data[\"img\"][\"axial\"] -> shape = batch x depth x pic x pic\n",
    "        vol_axial = data[\"img\"][self.naming[0]][0, :, :, :].to(self.device)\n",
    "        vol_axial = torch.stack((vol_axial,)*3, axis=1)\n",
    "\n",
    "        vol_sagit = data[\"img\"][self.naming[1]][0, :, :, :].to(self.device)\n",
    "        vol_sagit = torch.stack((vol_sagit,)*3, axis=1)\n",
    "\n",
    "        vol_coron = data[\"img\"][self.naming[2]][0, :, :, :].to(self.device)\n",
    "        vol_coron = torch.stack((vol_coron,)*3, axis=1)\n",
    "\n",
    "        label = torch.zeros(vol_axial.shape[0], self.y_len)  # init\n",
    "        for i, cl in enumerate(self.y_labels):\n",
    "            label[:, i] = data[cl]\n",
    "        label = label[0, :].to(self.device)\n",
    "\n",
    "        return vol_axial, vol_sagit, vol_coron, label\n",
    "\n",
    "    def apply_gap(self, vol_axial, vol_sagit, vol_coron):\n",
    "        \"\"\"\n",
    "        applies the average / rnn gap\n",
    "        \"\"\"\n",
    "        vol_axial = self.gap_axial(vol_axial).view(vol_axial.size(0), -1)\n",
    "        vol_sagit = self.gap_sagit(vol_sagit).view(vol_sagit.size(0), -1)\n",
    "        vol_coron = self.gap_coron(vol_coron).view(vol_coron.size(0), -1)\n",
    "\n",
    "        if self.rnn_gap:\n",
    "            # idea add spatial relation here\n",
    "            x = self.max_axial(vol_axial)[0]\n",
    "            y = self.max_sagit(vol_sagit)[0]\n",
    "            z = self.max_coron(vol_coron)[0]\n",
    "\n",
    "            w = torch.cat((x, y, z), 0)\n",
    "\n",
    "        else:\n",
    "            x = torch.max(vol_axial, 0, keepdim=True)[0]\n",
    "            y = torch.max(vol_sagit, 0, keepdim=True)[0]\n",
    "            z = torch.max(vol_coron, 0, keepdim=True)[0]\n",
    "\n",
    "            w = torch.cat((x, y, z), 1)[0]\n",
    "\n",
    "        return w\n",
    "\n",
    "    def forward(self, data, update=True):\n",
    "        \"\"\"\n",
    "        perform the forward pass and update\n",
    "        \"\"\"\n",
    "        # get the required input\n",
    "        vol_axial, vol_sagit, vol_coron, label = self.get_input_image(data)\n",
    "\n",
    "        # apply the main networks\n",
    "        vol_axial = self.axial_net(vol_axial)\n",
    "        vol_sagit = self.sagit_net(vol_sagit)\n",
    "        vol_coron = self.coron_net(vol_coron)\n",
    "\n",
    "        # apply the gap\n",
    "        w = self.apply_gap(vol_axial, vol_sagit, vol_coron)\n",
    "\n",
    "        logit = self.classifier(w)\n",
    "        # accumulate losses\n",
    "        loss = 0\n",
    "        for i, cl in enumerate(self.y_labels):\n",
    "            loss += self.weighted_loss(logit[i], label[i], cl)\n",
    "        loss /= self.batch_update\n",
    "\n",
    "        out = self.sigmoid(logit)\n",
    "\n",
    "        if update:\n",
    "            loss.backward()\n",
    "            self.int_count += 1\n",
    "\n",
    "            if self.int_count > self.batch_update:\n",
    "                # finally take the update step\n",
    "                self.int_count = 0\n",
    "                self.optimizer.step()\n",
    "                self.zero_grad()\n",
    "\n",
    "            return out\n",
    "        else:\n",
    "            tr_data = {}\n",
    "            tr_data[\"loss\"] = loss.item()\n",
    "            return out, label, tr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from deeptool.train_loop import test_one_batch\n",
    "from deeptool.parameters import get_all_args, compat_args\n",
    "args = get_all_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 dim test\n",
    "args.model_type = \"diagnosis\"\n",
    "args.dim = 3\n",
    "args = compat_args(args)\n",
    "test_one_batch(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dataloader.ipynb.\n",
      "Converted 01_architecture.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_parameters.ipynb.\n",
      "Converted 04_train_loop.ipynb.\n",
      "Converted 10_diagnosis.ipynb.\n",
      "Converted 20_dcgan.ipynb.\n",
      "Converted 21_introvae.ipynb.\n",
      "Converted 22_vqvae.ipynb.\n",
      "Converted 23_rnn_vae.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "82fdadc0-b84a-48d1-9b8e-d8a208951284"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
