{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model.diagnosis\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnosis\n",
    "\n",
    "> Structure for performing Diagnosis for 3D Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/diagnosis.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "     \n",
    "https://stanfordmlgroup.github.io/projects/mrnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import pdb\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import models\n",
    "from deeptool.abs_model import AbsModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Final Classification Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class Classify(nn.Module):\n",
    "    \"\"\"\n",
    "    The Classifier on top of the triplenet network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_dim, mid_dim, out_dim, p_drop=0.5):\n",
    "        \"\"\"init the classifier\"\"\"\n",
    "        super(Classify, self).__init__()\n",
    "        # reduction block\n",
    "        self.reduce = nn.Sequential(\n",
    "            nn.Linear(in_dim, mid_dim), nn.Dropout(p=p_drop), nn.ReLU(inplace=True),\n",
    "        )\n",
    "        # final block\n",
    "        self.fin_block = nn.Sequential(nn.Linear(mid_dim, out_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"perform forward calculation\"\"\"\n",
    "        # reduce\n",
    "        x = self.reduce(x)\n",
    "        x = self.fin_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed extension: Maintaining the spatial Relation using Recurrence\n",
    "\n",
    "<img src=\"img/diagnosis_rnn.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class ClassifyRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The Classifier on top of the triplenet network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device, input_size, hidden_size, n_layers=1):\n",
    "        \"\"\"init the classifier\"\"\"\n",
    "        super(ClassifyRNN, self).__init__()\n",
    "        self.device = device\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, n_layers).to(self.device)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        \"\"\"create zeros for hidden layer\"\"\"\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"perform forward calculation\"\"\"\n",
    "        x = x.view(-1, 1, self.input_size)\n",
    "        # create hidden dimension\n",
    "        hidden = self.init_hidden()\n",
    "        # apply GRU\n",
    "        _, hidden = self.gru(x, hidden)\n",
    "        # use hidden for final linear layer (equal to last output)\n",
    "        return hidden.view(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Complete Network with Backbone and Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "\n",
    "class Compressor(nn.Module):\n",
    "    \"\"\"\n",
    "    This class compresses the data from all slices to be only a vector.\n",
    "    Contains the backbone and the pooling\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        device,\n",
    "        args,\n",
    "        train_data=None,\n",
    "        backbone=\"resnet18\",\n",
    "        training=True,\n",
    "        document=True,\n",
    "    ):\n",
    "        super(Compressor, self).__init__()\n",
    "\n",
    "        # general defines\n",
    "        self.device = device\n",
    "        self.backbone = args.mrnet_backbone\n",
    "        self.y_labels = args.classes\n",
    "        self.y_len = len(self.y_labels)\n",
    "        self.naming = args.perspectives\n",
    "        \n",
    "        # average together\n",
    "        self.rnn_gap = args.mrnet_rnn_gap\n",
    "        self.hidden_dim = args.mrnet_hidden_dim\n",
    "        \n",
    "        # define whether to use one network or multiple ones\n",
    "        self.single_stream = args.mrnet_singlestream\n",
    "        \n",
    "        # build backbone networks\n",
    "        self.axial_net = self.build_backbone(training)\n",
    "        self.sagit_net = self.build_backbone(training)\n",
    "        self.coron_net = self.build_backbone(training)\n",
    "\n",
    "        # build gap and classifier\n",
    "        # apply average pooling\n",
    "        self.gap_axial = nn.AdaptiveAvgPool2d(1).to(self.device)\n",
    "        self.gap_sagit = nn.AdaptiveAvgPool2d(1).to(self.device)\n",
    "        self.gap_coron = nn.AdaptiveAvgPool2d(1).to(self.device)\n",
    "        \n",
    "        if self.rnn_gap:\n",
    "            # only for the avergae case\n",
    "            if self.backbone in (\"resnet18\", \"vgg\", \"squeeze\"):\n",
    "                self.input_rnn = 512\n",
    "            else:\n",
    "                self.input_rnn = 256\n",
    "\n",
    "            # the RNN gapping\n",
    "            self.max_axial = ClassifyRNN(self.device, self.input_rnn, self.hidden_dim)\n",
    "            self.max_sagit = ClassifyRNN(self.device, self.input_rnn, self.hidden_dim)\n",
    "            self.max_coron = ClassifyRNN(self.device, self.input_rnn, self.hidden_dim)\n",
    "                \n",
    "        # redefine if single stream\n",
    "        if self.single_stream:\n",
    "            # make them all reference the same network\n",
    "            self.sagit_net = self.axial_net\n",
    "            self.coron_net = self.axial_net\n",
    "\n",
    "            if self.rnn_gap:\n",
    "                self.max_sagit = self.max_axial\n",
    "                self.max_coron = self.max_axial\n",
    "        \n",
    "    def build_backbone(self, training):\n",
    "        \"\"\"\n",
    "        Builds the desired backbone\n",
    "        \"\"\"\n",
    "        if self.backbone == \"resnet18\":\n",
    "            resnet = models.resnet18(pretrained=training)\n",
    "            modules = list(resnet.children())[:-1]\n",
    "            local_net = nn.Sequential(*modules)\n",
    "            for param in local_net.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        elif self.backbone == \"resnet34\":\n",
    "            resnet = models.resnet34(pretrained=training)\n",
    "            modules = list(resnet.children())[:-1]\n",
    "            local_net = nn.Sequential(*modules)\n",
    "            for param in local_net.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        elif self.backbone == \"alexnet\":\n",
    "            local_net = models.alexnet(pretrained=training)\n",
    "            local_net = local_net.features\n",
    "\n",
    "        elif self.backbone == \"vgg\":\n",
    "            local_net = models.vgg11(pretrained=training)\n",
    "            local_net = local_net.features\n",
    "\n",
    "        elif self.backbone == \"squeeze\":\n",
    "            local_net = models.squeezenet1_1(pretrained=training)\n",
    "            local_net = local_net.features\n",
    "\n",
    "        return local_net\n",
    "    \n",
    "    def apply_gap(self, vol_axial, vol_sagit, vol_coron):\n",
    "        \"\"\"\n",
    "        applies the average / rnn gap\n",
    "        \"\"\"\n",
    "        vol_axial = self.gap_axial(vol_axial).view(vol_axial.size(0), -1)\n",
    "        vol_sagit = self.gap_sagit(vol_sagit).view(vol_sagit.size(0), -1)\n",
    "        vol_coron = self.gap_coron(vol_coron).view(vol_coron.size(0), -1)\n",
    "\n",
    "        if self.rnn_gap:\n",
    "            # idea add spatial relation here\n",
    "            x = self.max_axial(vol_axial)[0]\n",
    "            y = self.max_sagit(vol_sagit)[0]\n",
    "            z = self.max_coron(vol_coron)[0]\n",
    "\n",
    "            w = torch.cat((x, y, z), 0)\n",
    "\n",
    "        else:\n",
    "            x = torch.max(vol_axial, 0, keepdim=True)[0]\n",
    "            y = torch.max(vol_sagit, 0, keepdim=True)[0]\n",
    "            z = torch.max(vol_coron, 0, keepdim=True)[0]\n",
    "\n",
    "            w = torch.cat((x, y, z), 1)[0]\n",
    "\n",
    "        return w\n",
    "    \n",
    "    def forward(self, vol_axial, vol_sagit, vol_coron):\n",
    "        # apply the main networks\n",
    "        vol_axial = self.axial_net(vol_axial)\n",
    "        vol_sagit = self.sagit_net(vol_sagit)\n",
    "        vol_coron = self.coron_net(vol_coron)\n",
    "\n",
    "        # apply the gap\n",
    "        w = self.apply_gap(vol_axial, vol_sagit, vol_coron)\n",
    "        \n",
    "        return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The TripleNet with Losses and bringing it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from deeptool.model.mocoae import momentumContrastiveLoss, momentum_update, copy_q2k_params, concat_all_gather\n",
    "\n",
    "class TripleMRNet(AbsModel):\n",
    "    \"\"\"\n",
    "    adapted from https://github.com/yashbhalgat/MRNet-Competition\n",
    "    with the knowledge of: https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002699\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        device,\n",
    "        args,\n",
    "        train_data=None,\n",
    "        backbone=\"resnet18\",\n",
    "        training=True,\n",
    "        document=True,\n",
    "    ):\n",
    "        super(TripleMRNet, self).__init__(args)\n",
    "        \n",
    "        # mid layer outcome\n",
    "        self.rnn_gap = args.mrnet_rnn_gap\n",
    "        self.hidden_dim = args.mrnet_hidden_dim\n",
    "\n",
    "        # general defines\n",
    "        self.device = device\n",
    "        self.backbone = args.mrnet_backbone\n",
    "        self.y_labels = args.classes\n",
    "        self.y_len = len(self.y_labels)\n",
    "        self.naming = args.perspectives\n",
    "\n",
    "        # depending on whether train_data is specified\n",
    "        if train_data == None:\n",
    "            self.weights = {}\n",
    "            self.weights[\"abn\"] = [0.81, 0.19]\n",
    "            self.weights[\"acl\"] = [0.23, 0.77]\n",
    "            self.weights[\"men\"] = [0.43, 0.57]\n",
    "        else:\n",
    "            self.weights = train_data.weights\n",
    "\n",
    "        # picture center cropping to 224 resolution\n",
    "        self.pic_size = 224\n",
    "        self.pad = int((args.pic_size - self.pic_size) / 2)\n",
    "        self.factor = 1  # 1130 / 208  # inverse factor\n",
    "\n",
    "        # internal count for updating\n",
    "        self.int_count = 0\n",
    "        self.batch_update = args.mrnet_batch_update\n",
    "        self.label_smoothing = args.mrnet_label_smoothing\n",
    "        \n",
    "        # the actual big backbone network\n",
    "        self.compressor = Compressor(device, args, train_data, backbone, training, document).to(self.device)\n",
    "        \n",
    "        # the Momentum Contrastive bool\n",
    "        self.moco = args.mrnet_moco\n",
    "        \n",
    "        self.forward= self.forward_moco if self.moco else self.forward_normal\n",
    "        \n",
    "        # add classifier\n",
    "        self.add_classifier()\n",
    "        \n",
    "        # final sigmoid layer\n",
    "        self.sigmoid = nn.Sigmoid().to(self.device)\n",
    "\n",
    "        # define optimizer\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=args.lr)\n",
    "        \n",
    "        # init all parts relevant for moco\n",
    "        self.init_moco(args, backbone, training) if self.moco else None\n",
    "        \n",
    "    def init_moco(self, args, backbone, training):\n",
    "        \"\"\"initialise all parts connected to MomentumContrastiveLearning\"\"\"\n",
    "        # add a second compressor if moco is active\n",
    "        self.m_compressor = Compressor(self.device, args, None, backbone, training, document).to(self.device)\n",
    "    \n",
    "    def add_classifier(self):\n",
    "        \"\"\"\n",
    "        add the final classification part\n",
    "        \"\"\"\n",
    "        if self.rnn_gap:\n",
    "            self.classifier = Classify(3 * self.hidden_dim, self.hidden_dim, self.y_len).to(self.device)\n",
    "        else:\n",
    "            # only for the average case\n",
    "            if self.backbone in (\"resnet18\", \"vgg\", \"squeeze\", \"resnet34\"):\n",
    "                self.classifier = Classify(3 * 512, self.hidden_dim, self.y_len).to(\n",
    "                    self.device\n",
    "                )\n",
    "            elif self.backbone == \"alexnet\":\n",
    "                self.classifier = Classify(3 * 256, self.hidden_dim, self.y_len).to(\n",
    "                    self.device\n",
    "                )\n",
    "\n",
    "    def weighted_loss(self, prediction, target, cl):\n",
    "        \"\"\"\n",
    "        Calculate the weighted loss with label smoothing \n",
    "        \"\"\"\n",
    "        # determin the weights\n",
    "        weights_npy = np.array([self.weights[cl][int(target)]])\n",
    "        weights_tensor = torch.FloatTensor(weights_npy)\n",
    "        weights_tensor = weights_tensor.to(self.device)[0]\n",
    "\n",
    "        # smooth the labels\n",
    "        if self.label_smoothing > 0:\n",
    "            target = target.add(self.label_smoothing).div(2)\n",
    "\n",
    "        # calculate binary cross entropy\n",
    "        loss = F.binary_cross_entropy_with_logits(\n",
    "            prediction, target, weight=Variable(weights_tensor)\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def watch_progress(self, valid_loader, iteration):\n",
    "        \"\"\"Outsourced to Tracker\"\"\"\n",
    "        self.tracker.get_accuracy(self, valid_loader, iteration)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def get_vol(self, data, name):\n",
    "        \"\"\"\n",
    "        helper func to load values\n",
    "        \"\"\"\n",
    "        vol = data['img'][name]\n",
    "        \n",
    "        # two volumes if moco is active\n",
    "        if self.moco:\n",
    "            vol0 = vol[0][0, :, :, :].to(self.device)\n",
    "            vol0 = torch.stack((vol0,) * 3, axis=1)\n",
    "            \n",
    "            vol1 = vol[1][0, :, :, :].to(self.device)\n",
    "            vol1 = torch.stack((vol1,) * 3, axis=1)\n",
    "            return vol0, vol1\n",
    "        \n",
    "        else:\n",
    "            # no stacking necessary\n",
    "            vol = vol[0, :, :, :].to(self.device)\n",
    "            return vol\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def get_input_image(self, data):\n",
    "        \"\"\"\n",
    "        take the input from the stack and give the single volumes\n",
    "        \"\"\"\n",
    "        # get the three volumes from the dictionary\n",
    "        # data[\"img\"][\"axial\"] -> shape = batch x depth x pic x pic\n",
    "        vol_axial = self.get_vol(data, self.naming[0])\n",
    "        vol_sagit = self.get_vol(data, self.naming[1])\n",
    "        vol_coron = self.get_vol(data, self.naming[2])\n",
    "\n",
    "        label = torch.zeros(vol_axial.shape[0], self.y_len)  # init\n",
    "        for i, cl in enumerate(self.y_labels):\n",
    "            label[:, i] = data[cl]\n",
    "        label = label[0, :].to(self.device)\n",
    "\n",
    "        return vol_axial, vol_sagit, vol_coron, label\n",
    "    \n",
    "    def forward_moco(self, data, update=True):\n",
    "        \"\"\"\n",
    "        perform forward pass in moco mode\n",
    "        \"\"\"\n",
    "        # get the required input\n",
    "        vol_axial, vol_sagit, vol_coron, label = self.get_input_image(data)\n",
    "        \n",
    "        # compress to the (256) vector\n",
    "        w = self.compressor(vol_axial[0], vol_sagit[0], vol_coron[0])\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward_normal(self, data, update=True):\n",
    "        \"\"\"\n",
    "        perform the forward pass and update in normal mode\n",
    "        \"\"\"\n",
    "        # get the required input\n",
    "        vol_axial, vol_sagit, vol_coron, label = self.get_input_image(data)\n",
    "        \n",
    "        # compress to the (256) vector\n",
    "        w = self.compressor(vol_axial, vol_sagit, vol_coron)\n",
    "\n",
    "        logit = self.classifier(w)\n",
    "        # accumulate losses\n",
    "        loss = 0\n",
    "        for i, cl in enumerate(self.y_labels):\n",
    "            loss += self.weighted_loss(logit[i], label[i], cl)\n",
    "        loss /= self.batch_update\n",
    "\n",
    "        out = self.sigmoid(logit)\n",
    "\n",
    "        if update:\n",
    "            loss.backward()\n",
    "            self.int_count += 1\n",
    "\n",
    "            if self.int_count > self.batch_update:\n",
    "                # finally take the update step\n",
    "                self.int_count = 0\n",
    "                self.optimizer.step()\n",
    "                self.zero_grad()\n",
    "\n",
    "            return out\n",
    "        else:\n",
    "            tr_data = {}\n",
    "            tr_data[\"loss\"] = loss.item()\n",
    "            return out, label, tr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from deeptool.train_loop import test_one_batch\n",
    "from deeptool.parameters import get_all_args, compat_args\n",
    "\n",
    "args = get_all_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dataloader.ipynb.\n",
      "Converted 01_architecture.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_parameters.ipynb.\n",
      "Converted 04_train_loop.ipynb.\n",
      "Converted 05_abstract_model.ipynb.\n",
      "Converted 10_diagnosis.ipynb.\n",
      "Converted 20_dcgan.ipynb.\n",
      "Converted 21_introvae.ipynb.\n",
      "Converted 22_vqvae.ipynb.\n",
      "Converted 23_bigan.ipynb.\n",
      "Converted 24_mocoae.ipynb.\n",
      "Converted 33_rnn_vae.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
