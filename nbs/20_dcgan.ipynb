{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model.dcgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN\n",
    "\n",
    "> Model for Training 2 and 3 dim GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/dcgan.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "     \n",
    "https://towardsdatascience.com/fake-face-generator-using-dcgan-model-ae9322ccfd65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "# General Includes\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch import autograd\n",
    "\n",
    "# Personal includes\n",
    "from deeptool.architecture import Decoder, Discriminator\n",
    "from deeptool.utils import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class DCGAN(nn.Module):\n",
    "    \"\"\"\n",
    "    Modification of the DCGAN-Paper https://arxiv.org/pdf/1511.06434.pdf for 3-Dimensional tasks in MR-Imaging\n",
    "    oriented on: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device, args):\n",
    "        \"\"\"\n",
    "        Setup the general architecture for the DCGAN model, composed of:\n",
    "        Generator, Discriminator\n",
    "        \"\"\"\n",
    "        super(DCGAN, self).__init__()\n",
    "        # dimension of networks (2d conv or 3d conv)\n",
    "        self.dim = args.dim\n",
    "\n",
    "        # Number of channels depending on perspectives\n",
    "        self.device = device\n",
    "        self.n_chan = len(args.perspectives)\n",
    "\n",
    "        # Generator\n",
    "        self.generator = Decoder(args).to(self.device)\n",
    "        \n",
    "\n",
    "        # Encoding dimension\n",
    "        self.n_z = args.n_z\n",
    "        self.batch_size = args.batch_size\n",
    "\n",
    "        # Fixed noise to visualize progression\n",
    "        self.fixed_noise = torch.randn(\n",
    "            self.batch_size, self.n_z, device=self.device)\n",
    "\n",
    "        # lambda factor for gradient penatly\n",
    "        self.lam = args.lam\n",
    "\n",
    "        # Loss to be optimized for dcgan\n",
    "        self.loss = nn.BCELoss()\n",
    "\n",
    "        self.real_label = 1\n",
    "        self.fake_label = 0\n",
    "\n",
    "        if args.wgan == True:\n",
    "            self.name = \"wgan\"\n",
    "            self.forward = self.forward_wgan     \n",
    "            # Discriminator\n",
    "            self.discriminator = Discriminator(args, wgan=True).to(self.device)\n",
    "            \n",
    "        else:\n",
    "            self.name = \"dcgan\"\n",
    "            self.forward = self.forward_dcgan\n",
    "            # Discriminator\n",
    "            self.discriminator = Discriminator(args, wgan=False).to(self.device)\n",
    "\n",
    "        # Optimizers\n",
    "        self.optimizerGen = optim.Adam(\n",
    "            self.generator.parameters(), lr=args.lr, betas=(0.5, 0.999))\n",
    "        self.optimizerDis = optim.Adam(\n",
    "            self.discriminator.parameters(), lr=args.lr, betas=(0.5, 0.999))\n",
    "\n",
    "        # Setup the tracker to visualize the progress\n",
    "        if args.track:\n",
    "            self.tracker = Tracker(args, log_view=False)\n",
    "        \n",
    "\n",
    "    def watch_progress(self, test_data, iteration):\n",
    "        \"\"\"\n",
    "        Outsourced to Tracker\n",
    "        \"\"\"\n",
    "        self.tracker.track_progress(self, test_data, iteration)\n",
    "\n",
    "    def calc_gradient_penalty(self, real_data, fake_data):\n",
    "        \"\"\"\n",
    "        Apply the gradient Penalty for Discriminator training\n",
    "        This is responsible for ensuring the Lipschitz constraint,\n",
    "        which is required to ensure the Wasserstein distance.\n",
    "        modified from: https://github.com/caogang/wgan-gp/blob/master/gan_cifar10.py \n",
    "        \"\"\"\n",
    "        # Asssign random factor alpha between 0 and 1\n",
    "        sh = real_data.shape\n",
    "        b_size = sh[0]\n",
    "        alpha = torch.rand(b_size, 1)\n",
    "        alpha = alpha.expand(b_size, int(\n",
    "            real_data.nelement()/b_size)).contiguous().view(sh)\n",
    "        alpha = alpha.to(self.device)\n",
    "\n",
    "        # interpolating as disc input\n",
    "        interpolates = (alpha * real_data +\n",
    "                        ((1 - alpha) * fake_data)).to(self.device)\n",
    "        interpolates = autograd.Variable(interpolates, requires_grad=True)\n",
    "\n",
    "        # evaluate discriminator\n",
    "        disc_interpolates = self.discriminator(interpolates)\n",
    "\n",
    "        # calculate gradients\n",
    "        gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                                  grad_outputs=torch.ones(\n",
    "                                      disc_interpolates.size()).to(self.device),\n",
    "                                  create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        gradients = gradients.view(gradients.size(0), -1)\n",
    "\n",
    "        # constrain gradients\n",
    "        gradient_penalty = ((gradients.norm(2, dim=1) - 1)\n",
    "                            ** 2).mean() * self.lam\n",
    "\n",
    "        return gradient_penalty\n",
    "\n",
    "    def sample_noise(self, batch_size, update):\n",
    "        \"\"\"\n",
    "        Sample the latent noise required for training\n",
    "        \"\"\"\n",
    "        if update:\n",
    "            return torch.randn(batch_size, self.n_z, device=self.device)\n",
    "        return self.fixed_noise\n",
    "\n",
    "    def forward_wgan(self, data, update=True):\n",
    "        \"\"\"\n",
    "        Calculate output and update networks with wgan\n",
    "        \"\"\"\n",
    "        # get the image data\n",
    "        real_gpu = data[\"img\"].to(self.device)\n",
    "\n",
    "        # (1) Update D network: maximize D(x) - D(G(z))\n",
    "        # 1.1 Train with all-real batch\n",
    "        self.discriminator.zero_grad()\n",
    "        b_size = real_gpu.size(0)\n",
    "        output = self.discriminator(real_gpu).view(-1)\n",
    "        errD_real = -torch.mean(output)\n",
    "\n",
    "        # 1.2 Train with all-fake batch\n",
    "        noise = self.sample_noise(b_size, update)\n",
    "        fake = self.generator(noise)\n",
    "        output = self.discriminator(fake.detach()).view(-1)\n",
    "        errD_fake = torch.mean(output)\n",
    "\n",
    "        # 1.3 assign Gradient penalty\n",
    "        gradient_penalty = self.calc_gradient_penalty(real_gpu, fake.detach())\n",
    "\n",
    "        # sum the losses up\n",
    "        errD = errD_fake + errD_real + gradient_penalty\n",
    "\n",
    "        # Update Discriminator\n",
    "        if update:\n",
    "            errD.backward()\n",
    "            self.optimizerDis.step()\n",
    "\n",
    "        # (2) Update G network: maximize D(G(z))\n",
    "        self.generator.zero_grad()\n",
    "        output = self.discriminator(fake).view(-1)\n",
    "        errG = -torch.mean(output)\n",
    "\n",
    "        # Update Generator\n",
    "        if update:\n",
    "            errG.backward()\n",
    "            self.optimizerGen.step()\n",
    "            return fake\n",
    "\n",
    "        else:\n",
    "            # Track all relevant losses\n",
    "            tr_data = {}\n",
    "            tr_data[\"errD\"] = errD.item()\n",
    "            tr_data[\"errG\"] = errG.item()\n",
    "            tr_data[\"D_x\"] = errD_real.item()\n",
    "            tr_data[\"D_G_z1\"] = errD_fake.item()\n",
    "            tr_data[\"D_G_z2\"] = output.mean().item()\n",
    "            # Return losses and fake data\n",
    "            return fake, tr_data\n",
    "\n",
    "    def forward_dcgan(self, data, update=True):\n",
    "        \"\"\"\n",
    "        Calculate output and update networks with dcgan\n",
    "        \"\"\"\n",
    "        # get the image data\n",
    "        real_gpu = data[\"img\"].to(self.device)\n",
    "\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        # 1.1 Train with all-real batch\n",
    "        self.discriminator.zero_grad()\n",
    "        b_size = real_gpu.size(0)\n",
    "        label = torch.full((b_size,), self.real_label, device=self.device)\n",
    "        output = self.discriminator(real_gpu).view(-1)\n",
    "        errD_real = self.loss(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # 1.2 Train with all-fake batch\n",
    "        noise = self.sample_noise(b_size, update)\n",
    "        fake = self.generator(noise)\n",
    "        output = self.discriminator(fake.detach()).view(-1)\n",
    "        label.fill_(self.fake_label)\n",
    "        errD_fake = self.loss(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_fake.item() + errD_real.item()\n",
    "\n",
    "        # Update Discriminator\n",
    "        if update:\n",
    "            self.optimizerDis.step()\n",
    "\n",
    "        # (2) Update G network: maximize 1 - log(D(G(z)))\n",
    "        self.generator.zero_grad()\n",
    "        label.fill_(self.real_label)\n",
    "        output = self.discriminator(fake).view(-1)\n",
    "        errG = self.loss(output, label)\n",
    "        errG.backward()\n",
    "\n",
    "        # Update Generator\n",
    "        if update:\n",
    "            self.optimizerGen.step()\n",
    "            return fake\n",
    "\n",
    "        else:\n",
    "            # Track all relevant losses\n",
    "            tr_data = {}\n",
    "            tr_data[\"errD\"] = errD\n",
    "            tr_data[\"errG\"] = errG.item()\n",
    "            tr_data[\"D_x\"] = D_x\n",
    "            tr_data[\"D_G_z1\"] = D_G_z1\n",
    "            tr_data[\"D_G_z2\"] = output.mean().item()\n",
    "            # Return losses and fake data\n",
    "            return fake, tr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from deeptool.train_loop import test_one_batch\n",
    "from deeptool.parameters import get_all_args, compat_args\n",
    "args = get_all_args()\n",
    "args.pic_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 dim test\n",
    "args.model_type = \"dcgan\"\n",
    "args.dim = 3\n",
    "args = compat_args(args)\n",
    "test_one_batch(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 dim test\n",
    "args.dim = 2\n",
    "args = compat_args(args)\n",
    "test_one_batch(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dataloader.ipynb.\n",
      "Converted 01_architecture.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_parameters.ipynb.\n",
      "Converted 04_train_loop.ipynb.\n",
      "Converted 10_diagnosis.ipynb.\n",
      "Converted 20_dcgan.ipynb.\n",
      "Converted 21_introvae.ipynb.\n",
      "Converted 22_vqvae.ipynb.\n",
      "Converted 23_rnn_vae.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
